{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Mkps/nvidia_workshop/blob/main/Profiling_CUDA_Advanced.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Jupyter notebook is a web based environment for interactive computing. It is capable of running code in a wide variety of programming languages. The notebook consists of cells which can be of type code or markdown (by default, new cells are created as code cells). You can execute the content of code cells by clicking the Run button. Cells which are actively running code will show a 'Play' icon and cells which have completed will show a green tick.\n",
        "\n",
        "**Connect to GPU runtime**: If using Google Colab, please ensure you have this notebook enabled with GPU before running (Runtime->Change runtime type). If you are not using Google Colab you can ignore this instruction.\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?export&id=1rroMUCXRqssxsUNo29qbkeYjqy792BsE\"/>"
      ],
      "metadata": {
        "id": "lai7PEwwPAZF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Installing NVIDIA Nsight System and Compute"
      ],
      "metadata": {
        "id": "vUxmly7CPGIr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Installing nsight-systems-2022.4.1 & nsight-compute-2022.1.1\n",
        "!apt-get update -y && \\\n",
        "     DEBIAN_FRONTEND=noninteractive apt-get install -y --no-install-recommends \\\n",
        "         apt-transport-https \\\n",
        "         ca-certificates \\\n",
        "         gnupg \\\n",
        "         wget && \\\n",
        "     rm -rf /var/lib/apt/lists/*\n",
        "!wget -qO - https://developer.download.nvidia.com/devtools/repos/ubuntu2004/amd64/nvidia.pub | apt-key add - && \\\n",
        "     echo \"deb https://developer.download.nvidia.com/devtools/repos/ubuntu2004/amd64/ /\" >> /etc/apt/sources.list.d/nsight.list && \\\n",
        "     apt-get update -y && \\\n",
        "     DEBIAN_FRONTEND=noninteractive apt-get install -y --no-install-recommends \\\n",
        "         nsight-systems-2022.1.1 nsight-compute-2022.1.1 && \\\n",
        "     rm -rf /var/lib/apt/lists/*\n",
        "\n",
        "# setting environment variable path\n",
        "import os\n",
        "os.environ[\"PATH\"] = \"/usr/local/bin\" + os.pathsep + os.getenv(\"PATH\")"
      ],
      "metadata": {
        "id": "uEDasdxZ6Fz1",
        "outputId": "7a727ac1-a4e1-4293-b8fe-c0849ed6d76b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r0% [Working]\r            \rGet:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,626 B]\n",
            "\r0% [Waiting for headers] [Waiting for headers] [1 InRelease 3,626 B/3,626 B 100\r0% [Waiting for headers] [Waiting for headers] [Waiting for headers] [Waiting f\r                                                                               \rHit:2 https://ppa.launchpadcontent.net/c2d4u.team/c2d4u4.0+/ubuntu jammy InRelease\n",
            "\r0% [Waiting for headers] [Waiting for headers] [Connecting to ppa.launchpadcont\r                                                                               \rHit:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "\r0% [Waiting for headers] [Waiting for headers] [Connected to ppa.launchpadconte\r                                                                               \rHit:4 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "\r                                                                               \r0% [Waiting for headers] [Waiting for headers]\r                                              \rHit:5 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "\r0% [Waiting for headers] [Waiting for headers] [Connecting to ppa.launchpadcont\r                                                                               \rHit:6 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "\r0% [Waiting for headers] [Waiting for headers] [Connecting to ppa.launchpadcont\r                                                                               \rGet:7 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [119 kB]\n",
            "Hit:8 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:9 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [109 kB]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,267 kB]\n",
            "Get:11 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [1,343 kB]\n",
            "Get:12 http://security.ubuntu.com/ubuntu jammy-security InRelease [110 kB]\n",
            "Get:13 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,002 kB]\n",
            "Get:14 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [1,081 kB]\n",
            "Fetched 5,034 kB in 6s (870 kB/s)\n",
            "Reading package lists... Done\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "wget is already the newest version (1.21.2-2ubuntu1).\n",
            "ca-certificates is already the newest version (20230311ubuntu0.22.04.1).\n",
            "gnupg is already the newest version (2.2.27-3ubuntu2.1).\n",
            "gnupg set to manually installed.\n",
            "The following NEW packages will be installed:\n",
            "  apt-transport-https\n",
            "0 upgraded, 1 newly installed, 0 to remove and 22 not upgraded.\n",
            "Need to get 1,510 B of archives.\n",
            "After this operation, 169 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 apt-transport-https all 2.4.10 [1,510 B]\n",
            "Fetched 1,510 B in 0s (9,071 B/s)\n",
            "Selecting previously unselected package apt-transport-https.\n",
            "(Reading database ... 120875 files and directories currently installed.)\n",
            "Preparing to unpack .../apt-transport-https_2.4.10_all.deb ...\n",
            "Unpacking apt-transport-https (2.4.10) ...\n",
            "Setting up apt-transport-https (2.4.10) ...\n",
            "Warning: apt-key is deprecated. Manage keyring files in trusted.gpg.d instead (see apt-key(8)).\n",
            "OK\n",
            "Get:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,626 B]\n",
            "Get:2 https://ppa.launchpadcontent.net/c2d4u.team/c2d4u4.0+/ubuntu jammy InRelease [18.1 kB]\n",
            "Get:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\n",
            "Get:4 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease [18.1 kB]\n",
            "Get:5 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ Packages [44.5 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy InRelease [270 kB]\n",
            "Get:7 http://security.ubuntu.com/ubuntu jammy-security InRelease [110 kB]\n",
            "Get:8 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease [24.3 kB]\n",
            "Get:9 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease [23.8 kB]\n",
            "Get:10 https://ppa.launchpadcontent.net/c2d4u.team/c2d4u4.0+/ubuntu jammy/main Sources [2,197 kB]\n",
            "Get:11 https://ppa.launchpadcontent.net/c2d4u.team/c2d4u4.0+/ubuntu jammy/main amd64 Packages [1,128 kB]\n",
            "Get:12 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [119 kB]\n",
            "Get:13 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy/main amd64 Packages [21.7 kB]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [109 kB]\n",
            "Get:15 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy/main amd64 Packages [37.7 kB]\n",
            "Get:16 http://security.ubuntu.com/ubuntu jammy-security/restricted amd64 Packages [1,226 kB]\n",
            "Get:17 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy/main amd64 Packages [29.9 kB]\n",
            "Ign:18 https://developer.download.nvidia.com/devtools/repos/ubuntu2004/amd64  InRelease\n",
            "Get:19 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [518 kB]\n",
            "Get:20 http://archive.ubuntu.com/ubuntu jammy/multiverse amd64 Packages [266 kB]\n",
            "Get:21 https://developer.download.nvidia.com/devtools/repos/ubuntu2004/amd64  Release [496 B]\n",
            "Get:22 https://developer.download.nvidia.com/devtools/repos/ubuntu2004/amd64  Release.gpg [833 B]\n",
            "Get:23 http://archive.ubuntu.com/ubuntu jammy/restricted amd64 Packages [164 kB]\n",
            "Get:24 http://archive.ubuntu.com/ubuntu jammy/main amd64 Packages [1,792 kB]\n",
            "Get:25 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [1,081 kB]\n",
            "Get:26 https://developer.download.nvidia.com/devtools/repos/ubuntu2004/amd64  Packages [10.3 kB]\n",
            "Get:27 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,002 kB]\n",
            "Get:28 http://archive.ubuntu.com/ubuntu jammy/universe amd64 Packages [17.5 MB]\n",
            "Get:29 http://security.ubuntu.com/ubuntu jammy-security/multiverse amd64 Packages [44.0 kB]\n",
            "Get:30 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [1,252 kB]\n",
            "Get:31 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [1,343 kB]\n",
            "Get:32 http://archive.ubuntu.com/ubuntu jammy-updates/multiverse amd64 Packages [49.8 kB]\n",
            "Get:33 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,267 kB]\n",
            "Get:34 http://archive.ubuntu.com/ubuntu jammy-backports/universe amd64 Packages [28.1 kB]\n",
            "Get:35 http://archive.ubuntu.com/ubuntu jammy-backports/main amd64 Packages [50.4 kB]\n",
            "Fetched 31.7 MB in 3s (11.1 MB/s)\n",
            "Reading package lists... Done\n",
            "W: https://developer.download.nvidia.com/devtools/repos/ubuntu2004/amd64/Release.gpg: Key is stored in legacy trusted.gpg keyring (/etc/apt/trusted.gpg), see the DEPRECATION section in apt-key(8) for details.\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  libtinfo5 libxcb-icccm4 libxcb-image0 libxcb-keysyms1 libxcb-render-util0\n",
            "  libxcb-util1 libxcb-xinerama0\n",
            "The following NEW packages will be installed:\n",
            "  libtinfo5 libxcb-icccm4 libxcb-image0 libxcb-keysyms1 libxcb-render-util0\n",
            "  libxcb-util1 libxcb-xinerama0 nsight-compute-2022.1.1\n",
            "  nsight-systems-2022.1.1\n",
            "0 upgraded, 9 newly installed, 0 to remove and 22 not upgraded.\n",
            "Need to get 653 MB of archives.\n",
            "After this operation, 856 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 libtinfo5 amd64 6.3-2ubuntu0.1 [100 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxcb-xinerama0 amd64 1.14-3ubuntu3 [5,414 B]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxcb-icccm4 amd64 0.4.1-1.1build2 [11.5 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxcb-util1 amd64 0.4.0-1build2 [11.4 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxcb-image0 amd64 0.4.0-2 [11.5 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxcb-keysyms1 amd64 0.4.0-1build3 [8,746 B]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxcb-render-util0 amd64 0.3.9-1build3 [10.3 kB]\n",
            "Get:8 https://developer.download.nvidia.com/devtools/repos/ubuntu2004/amd64  nsight-compute-2022.1.1 2022.1.1.2-1 [412 MB]\n",
            "Get:9 https://developer.download.nvidia.com/devtools/repos/ubuntu2004/amd64  nsight-systems-2022.1.1 2022.1.1.61-1d07dc0 [241 MB]\n",
            "Fetched 653 MB in 26s (24.9 MB/s)\n",
            "Selecting previously unselected package libtinfo5:amd64.\n",
            "(Reading database ... 120879 files and directories currently installed.)\n",
            "Preparing to unpack .../0-libtinfo5_6.3-2ubuntu0.1_amd64.deb ...\n",
            "Unpacking libtinfo5:amd64 (6.3-2ubuntu0.1) ...\n",
            "Selecting previously unselected package libxcb-xinerama0:amd64.\n",
            "Preparing to unpack .../1-libxcb-xinerama0_1.14-3ubuntu3_amd64.deb ...\n",
            "Unpacking libxcb-xinerama0:amd64 (1.14-3ubuntu3) ...\n",
            "Selecting previously unselected package nsight-compute-2022.1.1.\n",
            "Preparing to unpack .../2-nsight-compute-2022.1.1_2022.1.1.2-1_amd64.deb ...\n",
            "Unpacking nsight-compute-2022.1.1 (2022.1.1.2-1) ...\n",
            "Selecting previously unselected package libxcb-icccm4:amd64.\n",
            "Preparing to unpack .../3-libxcb-icccm4_0.4.1-1.1build2_amd64.deb ...\n",
            "Unpacking libxcb-icccm4:amd64 (0.4.1-1.1build2) ...\n",
            "Selecting previously unselected package libxcb-util1:amd64.\n",
            "Preparing to unpack .../4-libxcb-util1_0.4.0-1build2_amd64.deb ...\n",
            "Unpacking libxcb-util1:amd64 (0.4.0-1build2) ...\n",
            "Selecting previously unselected package libxcb-image0:amd64.\n",
            "Preparing to unpack .../5-libxcb-image0_0.4.0-2_amd64.deb ...\n",
            "Unpacking libxcb-image0:amd64 (0.4.0-2) ...\n",
            "Selecting previously unselected package libxcb-keysyms1:amd64.\n",
            "Preparing to unpack .../6-libxcb-keysyms1_0.4.0-1build3_amd64.deb ...\n",
            "Unpacking libxcb-keysyms1:amd64 (0.4.0-1build3) ...\n",
            "Selecting previously unselected package libxcb-render-util0:amd64.\n",
            "Preparing to unpack .../7-libxcb-render-util0_0.3.9-1build3_amd64.deb ...\n",
            "Unpacking libxcb-render-util0:amd64 (0.3.9-1build3) ...\n",
            "Selecting previously unselected package nsight-systems-2022.1.1.\n",
            "Preparing to unpack .../8-nsight-systems-2022.1.1_2022.1.1.61-1d07dc0_amd64.deb ...\n",
            "Unpacking nsight-systems-2022.1.1 (2022.1.1.61-1d07dc0) ...\n",
            "Setting up libxcb-keysyms1:amd64 (0.4.0-1build3) ...\n",
            "Setting up nsight-compute-2022.1.1 (2022.1.1.2-1) ...\n",
            "Setting up libxcb-render-util0:amd64 (0.3.9-1build3) ...\n",
            "Setting up libxcb-icccm4:amd64 (0.4.1-1.1build2) ...\n",
            "Setting up libxcb-util1:amd64 (0.4.0-1build2) ...\n",
            "Setting up libxcb-image0:amd64 (0.4.0-2) ...\n",
            "Setting up libxcb-xinerama0:amd64 (1.14-3ubuntu3) ...\n",
            "Setting up libtinfo5:amd64 (6.3-2ubuntu0.1) ...\n",
            "Setting up nsight-systems-2022.1.1 (2022.1.1.61-1d07dc0) ...\n",
            "update-alternatives: using /opt/nvidia/nsight-systems/2022.1.1/target-linux-x64/nsys to provide /usr/local/bin/nsys (nsys) in auto mode\n",
            "update-alternatives: using /opt/nvidia/nsight-systems/2022.1.1/host-linux-x64/nsys-ui to provide /usr/local/bin/nsys-ui (nsys-ui) in auto mode\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.1) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's check the installed version of the NVIDIA profiler tools to ensure the installation was successfull."
      ],
      "metadata": {
        "id": "Ugc058o38_3O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nsys --version\n",
        "!echo \"---\"\n",
        "!ncu --version"
      ],
      "metadata": {
        "id": "qG5rPU3A9UXK",
        "outputId": "cd889115-0804-43fb-9a1d-f8a981748a58",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NVIDIA Nsight Systems version 2022.1.1.61-1d07dc0\n",
            "---\n",
            "NVIDIA (R) Nsight Compute Command Line Profiler\n",
            "Copyright (c) 2018-2022 NVIDIA Corporation\n",
            "Version 2022.3.0.0 (build 31729285) (public-release)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The expected output is\n",
        "\n",
        "```\n",
        "NVIDIA Nsight Systems version 2022.1.1.61-1d07dc0\n",
        "---\n",
        "NVIDIA (R) Nsight Compute Command Line Profiler\n",
        "Copyright (c) 2018-2022 NVIDIA Corporation\n",
        "Version 2022.1.1.0 (build 30914944) (public-release)\n",
        "```\n",
        "If your output is different, make sure you are connected to the runtime and re-run installation."
      ],
      "metadata": {
        "id": "ire_5sHB9eEl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# download the source code\n",
        "import gdown\n",
        "import os\n",
        "url = 'https://drive.google.com/uc?id=1FDsXtSVmqk8TI4tZvAMbYiS8761_gWLM&export=download'\n",
        "#url = 'https://drive.google.com/u/0/uc?export=download&confirm=1FDsXtSVmqk8TI4tZvAMbYiS8761_gWLM'\n",
        "output = '/home/code'\n",
        "gdown.download(url, output, quiet=False,proxy=None)\n",
        "!unzip /home/code -d /home\n",
        "!rm /home/code"
      ],
      "metadata": {
        "id": "65kOh-TMPYj0",
        "outputId": "5981b52c-0239-465a-ba97-637f57520fb8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1FDsXtSVmqk8TI4tZvAMbYiS8761_gWLM&export=download\n",
            "To: /home/code\n",
            "100%|██████████| 173k/173k [00:00<00:00, 97.2MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /home/code\n",
            "   creating: /home/source_code/\n",
            "   creating: /home/source_code/lab1/\n",
            "  inflating: /home/source_code/lab1/Makefile  \n",
            "  inflating: /home/source_code/lab1/miniWeather_serial.cpp  \n",
            "   creating: /home/source_code/lab1/.ipynb_checkpoints/\n",
            "  inflating: /home/source_code/lab1/.ipynb_checkpoints/Makefile-checkpoint  \n",
            "  inflating: /home/source_code/lab1/.ipynb_checkpoints/miniWeather_serial-checkpoint.cpp  \n",
            "  inflating: /home/source_code/lab1/.ipynb_checkpoints/miniWeather_serial-checkpoint.f90  \n",
            "  inflating: /home/source_code/lab1/miniWeather_serial.f90  \n",
            "   creating: /home/source_code/lab2/\n",
            "  inflating: /home/source_code/lab2/Makefile  \n",
            "   creating: /home/source_code/lab2/.ipynb_checkpoints/\n",
            "  inflating: /home/source_code/lab2/.ipynb_checkpoints/Makefile-checkpoint  \n",
            "  inflating: /home/source_code/lab2/.ipynb_checkpoints/miniWeather_openacc-checkpoint.cpp  \n",
            "  inflating: /home/source_code/lab2/.ipynb_checkpoints/miniWeather_openacc-checkpoint.f90  \n",
            "  inflating: /home/source_code/lab2/miniWeather_openacc.cpp  \n",
            "  inflating: /home/source_code/lab2/miniWeather_openacc.f90  \n",
            "   creating: /home/source_code/lab3/\n",
            "  inflating: /home/source_code/lab3/Makefile  \n",
            "   creating: /home/source_code/lab3/.ipynb_checkpoints/\n",
            "  inflating: /home/source_code/lab3/.ipynb_checkpoints/Makefile-checkpoint  \n",
            "  inflating: /home/source_code/lab3/.ipynb_checkpoints/miniWeather_openacc-checkpoint.cpp  \n",
            "  inflating: /home/source_code/lab3/.ipynb_checkpoints/miniWeather_openacc-checkpoint.f90  \n",
            "  inflating: /home/source_code/lab3/miniWeather_openacc.cpp  \n",
            "  inflating: /home/source_code/lab3/miniWeather_openacc.f90  \n",
            "   creating: /home/source_code/lab4/\n",
            "  inflating: /home/source_code/lab4/Makefile  \n",
            "   creating: /home/source_code/lab4/.ipynb_checkpoints/\n",
            "  inflating: /home/source_code/lab4/.ipynb_checkpoints/Makefile-checkpoint  \n",
            "  inflating: /home/source_code/lab4/.ipynb_checkpoints/miniWeather_openacc-checkpoint.cpp  \n",
            "  inflating: /home/source_code/lab4/.ipynb_checkpoints/miniWeather_openacc-checkpoint.f90  \n",
            "  inflating: /home/source_code/lab4/miniWeather_openacc.cpp  \n",
            "  inflating: /home/source_code/lab4/miniWeather_openacc.f90  \n",
            "   creating: /home/source_code/lab6/\n",
            "  inflating: /home/source_code/lab6/jacobi.cpp  \n",
            "  inflating: /home/source_code/lab6/jacobi_step1.cpp  \n",
            "  inflating: /home/source_code/lab6/jacobi_step2.cpp  \n",
            "  inflating: /home/source_code/lab6/jacobi_step3.cpp  \n",
            "  inflating: /home/source_code/lab6/jacobi_step4.cpp  \n",
            "  inflating: /home/source_code/lab6/jacobi_step5.cpp  \n",
            "  inflating: /home/source_code/lab6/jacobi_step6.cpp  \n",
            "  inflating: /home/source_code/lab6/jacobi_step7.cpp  \n",
            "  inflating: /home/source_code/lab6/jacobi_step8.cpp  \n",
            "  inflating: /home/source_code/lab6/Makefile  \n",
            "   creating: /home/source_code/lab6/.ipynb_checkpoints/\n",
            "  inflating: /home/source_code/lab6/.ipynb_checkpoints/jacobi-checkpoint.cpp  \n",
            "  inflating: /home/source_code/lab6/.ipynb_checkpoints/Makefile-checkpoint  \n",
            "  inflating: /home/source_code/lab6/.ipynb_checkpoints/jacobi_step1-checkpoint.cpp  \n",
            "  inflating: /home/source_code/lab6/.ipynb_checkpoints/jacobi_step4-checkpoint.cpp  \n",
            "  inflating: /home/source_code/lab6/.ipynb_checkpoints/jacobi_step5-checkpoint.cpp  \n",
            "  inflating: /home/source_code/lab6/.ipynb_checkpoints/jacobi_step6-checkpoint.cpp  \n",
            "  inflating: /home/source_code/lab6/.ipynb_checkpoints/jacobi_step7-checkpoint.cpp  \n",
            "  inflating: /home/source_code/lab6/.ipynb_checkpoints/jacobi_step8-checkpoint.cpp  \n",
            "  inflating: /home/source_code/lab6/.ipynb_checkpoints/jacobi_step2-checkpoint.cpp  \n",
            "  inflating: /home/source_code/lab6/.ipynb_checkpoints/jacobi_step3-checkpoint.cpp  \n",
            "   creating: /home/source_code/lab5/\n",
            "  inflating: /home/source_code/lab5/Makefile  \n",
            "  inflating: /home/source_code/lab5/miniWeather_openacc.cpp  \n",
            "   creating: /home/source_code/lab5/.ipynb_checkpoints/\n",
            "  inflating: /home/source_code/lab5/.ipynb_checkpoints/Makefile-checkpoint  \n",
            "  inflating: /home/source_code/lab5/.ipynb_checkpoints/miniWeather_openacc-checkpoint.cpp  \n",
            "  inflating: /home/source_code/lab5/.ipynb_checkpoints/miniWeather_openacc-checkpoint.f90  \n",
            "  inflating: /home/source_code/lab5/miniWeather_openacc.f90  \n",
            "   creating: /home/source_code/.ipynb_checkpoints/\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let' check we downloaded the source files."
      ],
      "metadata": {
        "id": "vHlLuax_7jsf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /home/source_code"
      ],
      "metadata": {
        "id": "ZH1AcSZ_7mHI",
        "outputId": "2aa6accc-be67-48ce-ccd1-ce726080a4ee",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "lab1  lab2  lab3  lab4\tlab5  lab6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The expected output is:\n",
        "\n",
        "```\n",
        "lab1  lab2  lab3  lab4\tlab5  lab6\n",
        "```\n",
        "\n",
        "If your output is different, make sure you are connected to the runtime and re-run the cell to download the source code."
      ],
      "metadata": {
        "id": "KTlkfqHo7o5K"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UBDQQBjRvIOe"
      },
      "source": [
        "Before we begin, let's execute the below cell to display information about the CUDA driver and GPUs running on the server by running the `nvidia-smi` command. To do this, execute the cell block below by clicking on the play button which appears when hovering over the cell with the mouse will run the code and you should see the output displayed beneath the code cell."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "pCnGZKvXvIOj",
        "outputId": "9df7e2a6-6fb7-46bb-854e-b55b113ce860",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tue Oct 10 10:15:58 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.105.17   Driver Version: 525.105.17   CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   44C    P8    10W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Lab 6 [Optional]\n"
      ],
      "metadata": {
        "id": "BvuztjS_yLJ4"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "acisGHkivIOl"
      },
      "source": [
        "\n",
        "###  Learning objectives\n",
        "The **goal** of this lab is to:\n",
        "\n",
        "- Learn how to profile an application using NVIDIA Nsight™ Systems and Nsight Compute (CUDA example)\n",
        "\n",
        "We do not intend to cover:\n",
        "\n",
        "- How to use the CUDA programming model\n",
        "- How to implement shared memory\n",
        "- Optimization methods\n",
        "\n",
        "**NOTE: All the below screenshots are from an NVIDIA A100 Tensor Core GPU.**\n",
        "\n",
        "Please read the below **Introduction notebook** before you start.\n",
        "\n",
        "In this lab, we will be porting the serial Jacobi code to the GPU using CUDA and obtaining the fastest performance possible. To achieve this, we need to consider Amdahl's law (please see the section on [Amdahl's Law and Scaling](profiling_lab1.ipynb#amdahls)) and remove as many performance limitations  as possible. Common performance limiters are:\n",
        "\n",
        "- Serial portion of the code on the CPU\n",
        "- Memory movements (Device To/From Host)\n",
        "- Latency as a result of launching GPU kernels\n",
        "- Not enough work to hide instruction latency\n",
        "- Non-efficient memory access pattern\n",
        "    - Uncoalesced memory accesses, lack of cache reuse, not using shared memory (Read more at [the NVIDIA Technical Blog](https://developer.nvidia.com/blog/boosting-application-performance-with-gpu-memory-prefetching/)) and [CUDA C Best Practices Guide](https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/)\n",
        "- Low arithmetic intensity (the ratio between compute work [FLOPs] and data movement [bytes])\n",
        "\n",
        "### Step 0: Analyze the Code\n",
        "\n",
        "In this lab, we will be working on the Jacobi iteration code that iteratively converges to the correct value by computing new values at each point from the average of neighboring  points.\n",
        "\n",
        "<!--<img src=\"images/jacobi_formula.png\" width=\"90%\">-->\n",
        "<img src=\"https://drive.google.com/uc?export=download&id=1w1tqEKAM0DyUmnQhUNMl2deW_lZrHGro\">\n",
        "\n",
        "\n",
        "**Understand and analyze** the code:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cat /home/source_code/lab6/jacobi.cpp"
      ],
      "metadata": {
        "id": "aeN3IkoxXGEo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cad4e49c-866e-4a76-bee7-70322a2ccc80"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "// Copyright (c) 2022 NVIDIA Corporation.  All rights reserved.\n",
            "\n",
            "#include <iostream>\n",
            "#include <iomanip>\n",
            "#include <ctime>\n",
            "#include <cmath>\n",
            "#include <limits>\n",
            "\n",
            "#define N 64\n",
            "\n",
            "#define IDX(i, j) ((j) + (i) * N)\n",
            "\n",
            "void allocate_memory (float** f, float** f_old, float** error) {\n",
            "    *f = (float*) malloc(N * N * sizeof(float));\n",
            "    *f_old = (float*) malloc(N * N * sizeof(float));\n",
            "    *error = (float*) malloc(sizeof(float));\n",
            "}\n",
            "\n",
            "void free_memory (float* f, float* f_old, float* error) {\n",
            "    free(f);\n",
            "    free(f_old);\n",
            "    free(error);\n",
            "}\n",
            "\n",
            "void initialize_data (float* f) {\n",
            "    // Set up simple sinusoidal boundary conditions\n",
            "    for (int j = 0; j < N; ++j) {\n",
            "        for (int i = 0; i < N; ++i) {\n",
            "\n",
            "            if (i == 0 || i == N-1) {\n",
            "                f[IDX(i,j)] = sin(j * 2 * M_PI / (N - 1));\n",
            "            }\n",
            "            else if (j == 0 || j == N-1) {\n",
            "                f[IDX(i,j)] = sin(i * 2 * M_PI / (N - 1));\n",
            "            }\n",
            "            else {\n",
            "                f[IDX(i,j)] = 0.0f;\n",
            "            }\n",
            "\n",
            "        }\n",
            "    }\n",
            "}\n",
            "\n",
            "void jacobi_step (float* f, float* f_old, float* error) {\n",
            "    for (int j = 1; j <= N-2; ++j) {\n",
            "        for (int i = 1; i <= N-2; ++i) {\n",
            "            f[IDX(i,j)] = 0.25f * (f_old[IDX(i+1,j)] + f_old[IDX(i-1,j)] +\n",
            "                                   f_old[IDX(i,j+1)] + f_old[IDX(i,j-1)]);\n",
            "\n",
            "            float df = f[IDX(i,j)] - f_old[IDX(i,j)];\n",
            "            *error += df * df;\n",
            "        }\n",
            "    }\n",
            "}\n",
            "\n",
            "void swap_data (float* f, float* f_old) {\n",
            "    for (int j = 1; j <= N-2; ++j) {\n",
            "        for (int i = 1; i <= N-2; ++i) {\n",
            "            f_old[IDX(i,j)] = f[IDX(i,j)];\n",
            "        }\n",
            "    }\n",
            "}\n",
            "\n",
            "int main () {\n",
            "    // Begin wall timing\n",
            "    std::clock_t start_time = std::clock();\n",
            "\n",
            "    float* f;\n",
            "    float* f_old;\n",
            "    float* error;\n",
            "\n",
            "    // Reserve space for the scalar field and the \"old\" copy of the data\n",
            "    allocate_memory(&f, &f_old, &error);\n",
            "\n",
            "    // Initialize data (we'll do this on both f and f_old, so that we don't\n",
            "    // have to worry about the boundary points later)\n",
            "    initialize_data(f);\n",
            "    initialize_data(f_old);\n",
            "\n",
            "    // Initialize error to a large number\n",
            "    *error = std::numeric_limits<float>::max();\n",
            "    const float tolerance = 1.e-4f;\n",
            "\n",
            "    // Iterate until we're converged (but set a cap on the maximum number of\n",
            "    // iterations to avoid any possible hangs)\n",
            "    const int max_iters = 1000;\n",
            "    int num_iters = 0;\n",
            "\n",
            "    while (*error > tolerance && num_iters < max_iters) {\n",
            "        // Initialize error to zero (we'll add to it the following step)\n",
            "        *error = 0.0f;\n",
            "\n",
            "        // Perform a Jacobi relaxation step\n",
            "        jacobi_step(f, f_old, error);\n",
            "\n",
            "        // Swap the old data and the new data\n",
            "        // We're doing this explicitly for pedagogical purposes, even though\n",
            "        // in this specific application a std::swap would have been OK\n",
            "        swap_data(f, f_old);\n",
            "\n",
            "        // Normalize the L2-norm of the error by the number of data points\n",
            "        // and then take the square root\n",
            "        *error = std::sqrt(*error / (N * N));\n",
            "\n",
            "        // Periodically print out the current error\n",
            "        if (num_iters % 25 == 0) {\n",
            "            std::cout << \"Error after iteration \" << num_iters << \" = \" << *error << std::endl;\n",
            "        }\n",
            "\n",
            "        // Increment the iteration count\n",
            "        ++num_iters;\n",
            "    }\n",
            "\n",
            "    // If we took fewer than max_iters steps and the error is below the tolerance,\n",
            "    // we succeeded. Otherwise, we failed.\n",
            "\n",
            "    if (*error <= tolerance && num_iters < max_iters) {\n",
            "        std::cout << \"Success!\" << std::endl;\n",
            "    }\n",
            "    else {\n",
            "        std::cout << \"Failure!\" << std::endl;\n",
            "        return -1;\n",
            "    }\n",
            "\n",
            "    // Clean up memory allocations\n",
            "    free_memory(f, f_old, error);\n",
            "\n",
            "    // End wall timing\n",
            "    double duration = (std::clock() - start_time) / (double) CLOCKS_PER_SEC;\n",
            "    std::cout << \"Run time = \" << std::setprecision(4) << duration << \" seconds\" << std::endl;\n",
            "\n",
            "    return 0;\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To obtain the best performance from the GPU and utilize the hardware, one should follow the cyclical process (analyze, parallelize, optimize). Start by compiling the code and running it on the CPU (**Note:** error will be printed periodically as output)."
      ],
      "metadata": {
        "id": "LrJ4b8TSXJ-_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "mtO2KCnlvIOn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7810370e-707f-43cd-8df3-ce19529b6b37"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc -o jacobi jacobi.cpp  \n"
          ]
        }
      ],
      "source": [
        "!cd /home/source_code/lab6 && make"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fzHDuN9evIOn"
      },
      "source": [
        "### Step 1: Instrument the Code to Find Bottlenecks\n",
        "\n",
        "Before we start  porting to the GPU, the first step is to identify the compute expensive part of the application to find  the performance bottlenecks. One way to do this would be to use the CPU walltime to measure different parts of the code. Another method would be adding NVIDIA Tools Extension software development kit (NVTX). We added the NVTX application programming interface (API) to the code.\n",
        "\n",
        "**Understand and analyze** the code:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cat /home/source_code/lab6/jacobi_step1.cpp"
      ],
      "metadata": {
        "id": "met9f5B0ZlgA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4a380fb3-a0fc-4c2a-a62b-137777317cd2"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "// Copyright (c) 2022 NVIDIA Corporation.  All rights reserved.\n",
            "\n",
            "#include <iostream>\n",
            "#include <iomanip>\n",
            "#include <cmath>\n",
            "#include <limits>\n",
            "#include <ctime>\n",
            "#include <nvToolsExt.h>\n",
            "\n",
            "#define N 64\n",
            "\n",
            "#define IDX(i, j) ((j) + (i) * N)\n",
            "\n",
            "void allocate_memory (float** f, float** f_old, float** error) {\n",
            "    *f = (float*) malloc(N * N * sizeof(float));\n",
            "    *f_old = (float*) malloc(N * N * sizeof(float));\n",
            "    *error = (float*) malloc(sizeof(float));\n",
            "}\n",
            "\n",
            "void free_memory (float* f, float* f_old, float* error) {\n",
            "    free(f);\n",
            "    free(f_old);\n",
            "    free(error);\n",
            "}\n",
            "\n",
            "void initialize_data (float* f) {\n",
            "    // Set up simple sinusoidal boundary conditions\n",
            "    for (int j = 0; j < N; ++j) {\n",
            "        for (int i = 0; i < N; ++i) {\n",
            "\n",
            "            if (i == 0 || i == N-1) {\n",
            "                f[IDX(i,j)] = sin(j * 2 * M_PI / (N - 1));\n",
            "            }\n",
            "            else if (j == 0 || j == N-1) {\n",
            "                f[IDX(i,j)] = sin(i * 2 * M_PI / (N - 1));\n",
            "            }\n",
            "            else {\n",
            "                f[IDX(i,j)] = 0.0f;\n",
            "            }\n",
            "\n",
            "        }\n",
            "    }\n",
            "}\n",
            "\n",
            "void jacobi_step (float* f, float* f_old, float* error) {\n",
            "    for (int j = 1; j <= N-2; ++j) {\n",
            "        for (int i = 1; i <= N-2; ++i) {\n",
            "            f[IDX(i,j)] = 0.25f * (f_old[IDX(i+1,j)] + f_old[IDX(i-1,j)] +\n",
            "                                   f_old[IDX(i,j+1)] + f_old[IDX(i,j-1)]);\n",
            "\n",
            "            float df = f[IDX(i,j)] - f_old[IDX(i,j)];\n",
            "            *error += df * df;\n",
            "        }\n",
            "    }\n",
            "}\n",
            "\n",
            "void swap_data (float* f, float* f_old) {\n",
            "    for (int j = 1; j <= N-2; ++j) {\n",
            "        for (int i = 1; i <= N-2; ++i) {\n",
            "            f_old[IDX(i,j)] = f[IDX(i,j)];\n",
            "        }\n",
            "    }\n",
            "}\n",
            "\n",
            "int main () {\n",
            "    // Begin wall timing\n",
            "    std::clock_t start_time = std::clock();\n",
            "\n",
            "    float* f;\n",
            "    float* f_old;\n",
            "    float* error;\n",
            "\n",
            "    // Reserve space for the scalar field and the \"old\" copy of the data\n",
            "    nvtxRangePush(\"Allocate memory\");\n",
            "    allocate_memory(&f, &f_old, &error);\n",
            "    nvtxRangePop();\n",
            "\n",
            "    // Initialize data (we'll do this on both f and f_old, so that we don't\n",
            "    // have to worry about the boundary points later)\n",
            "    nvtxRangePush(\"Initialize data\");\n",
            "    initialize_data(f);\n",
            "    initialize_data(f_old);\n",
            "    nvtxRangePop();\n",
            "\n",
            "    // Initialize error to a large number\n",
            "    *error = std::numeric_limits<float>::max();\n",
            "    const float tolerance = 1.e-4f;\n",
            "\n",
            "    // Iterate until we're converged (but set a cap on the maximum number of\n",
            "    // iterations to avoid any possible hangs)\n",
            "    const int max_iters = 1000;\n",
            "    int num_iters = 0;\n",
            "\n",
            "    while (*error > tolerance && num_iters < max_iters) {\n",
            "        // Initialize error to zero (we'll add to it the following step)\n",
            "        *error = 0.0f;\n",
            "\n",
            "        // Perform a Jacobi relaxation step\n",
            "        nvtxRangePush(\"Jacobi step\");\n",
            "        jacobi_step(f, f_old, error);\n",
            "        nvtxRangePop();\n",
            "\n",
            "        // Swap the old data and the new data\n",
            "        // We're doing this explicitly for pedagogical purposes, even though\n",
            "        // in this specific application a std::swap would have been OK\n",
            "        nvtxRangePush(\"Swap data\");\n",
            "        swap_data(f, f_old);\n",
            "        nvtxRangePop();\n",
            "\n",
            "        // Normalize the L2-norm of the error by the number of data points\n",
            "        // and then take the square root\n",
            "        *error = std::sqrt(*error / (N * N));\n",
            "\n",
            "        // Periodically print out the current error\n",
            "        if (num_iters % 25 == 0) {\n",
            "            std::cout << \"Error after iteration \" << num_iters << \" = \" << *error << std::endl;\n",
            "        }\n",
            "\n",
            "        // Increment the iteration count\n",
            "        ++num_iters;\n",
            "    }\n",
            "\n",
            "    // If we took fewer than max_iters steps and the error is below the tolerance,\n",
            "    // we succeeded. Otherwise, we failed.\n",
            "\n",
            "    if (*error <= tolerance && num_iters < max_iters) {\n",
            "        std::cout << \"Success!\" << std::endl;\n",
            "    }\n",
            "    else {\n",
            "        std::cout << \"Failure!\" << std::endl;\n",
            "        return -1;\n",
            "    }\n",
            "\n",
            "    // Clean up memory allocations\n",
            "    nvtxRangePush(\"Free memory\");\n",
            "    free_memory(f, f_old, error);\n",
            "    nvtxRangePop();\n",
            "\n",
            "    // End wall timing\n",
            "    double duration = (std::clock() - start_time) / (double) CLOCKS_PER_SEC;\n",
            "    std::cout << \"Run time = \" << std::setprecision(4) << duration << \" seconds\" << std::endl;\n",
            "\n",
            "    return 0;\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, compile the code and **profile** with `nsys` (Reminder: `--stats=true` shows the summary output that includes information about time spent in the various NVTX regions.) (Reminder: we need to link it against the right runtime library (`libnvToolsExt.so`))"
      ],
      "metadata": {
        "id": "fo_rHbR7ZmEt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "SwdWgjwovIOo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d71302da-0a12-4962-fa98-aa654cc25961"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc -o jacobi_step1 -x cu -lnvToolsExt -lineinfo jacobi_step1.cpp\n",
            "Warning: LBR backtrace method is not supported on this platform. DWARF backtrace method will be used.\n",
            "Error after iteration 0 = 0.0438475\n",
            "Error after iteration 25 = 0.0032022\n",
            "Error after iteration 50 = 0.00181223\n",
            "Error after iteration 75 = 0.00126184\n",
            "Error after iteration 100 = 0.000957702\n",
            "Error after iteration 125 = 0.000762262\n",
            "Error after iteration 150 = 0.000625323\n",
            "Error after iteration 175 = 0.000523902\n",
            "Error after iteration 200 = 0.000445912\n",
            "Error after iteration 225 = 0.000384343\n",
            "Error after iteration 250 = 0.000334796\n",
            "Error after iteration 275 = 0.000294325\n",
            "Error after iteration 300 = 0.000260843\n",
            "Error after iteration 325 = 0.00023282\n",
            "Error after iteration 350 = 0.000209104\n",
            "Error after iteration 375 = 0.000188812\n",
            "Error after iteration 400 = 0.00017127\n",
            "Error after iteration 425 = 0.000155952\n",
            "Error after iteration 450 = 0.000142454\n",
            "Error after iteration 475 = 0.000130462\n",
            "Error after iteration 500 = 0.000119732\n",
            "Error after iteration 525 = 0.000110069\n",
            "Error after iteration 550 = 0.000101323\n",
            "Success!\n",
            "Run time = 0.02769 seconds\n",
            "Generating '/tmp/nsys-report-44a1.qdstrm'\n",
            "[1/8] [========================100%] jacobi_step1.nsys-rep\n",
            "[2/8] [========================100%] jacobi_step1.sqlite\n",
            "[3/8] Executing 'nvtxsum' stats report\n",
            "\n",
            "NVTX Range Statistics:\n",
            "\n",
            " Time (%)  Total Time (ns)  Instances  Avg (ns)  Med (ns)  Min (ns)  Max (ns)  StdDev (ns)   Style        Range     \n",
            " --------  ---------------  ---------  --------  --------  --------  --------  -----------  -------  ---------------\n",
            "     76.2       20,086,355        555  36,191.6  31,529.0    31,197    95,258      8,774.3  PushPop  Jacobi step    \n",
            "     23.5        6,197,122        555  11,166.0  10,047.0     9,920    57,529      3,447.5  PushPop  Swap data      \n",
            "      0.2           54,104          1  54,104.0  54,104.0    54,104    54,104          0.0  PushPop  Initialize data\n",
            "      0.0            6,665          1   6,665.0   6,665.0     6,665     6,665          0.0  PushPop  Allocate memory\n",
            "      0.0            1,055          1   1,055.0   1,055.0     1,055     1,055          0.0  PushPop  Free memory    \n",
            "\n",
            "[4/8] Executing 'osrtsum' stats report\n",
            "\n",
            "Operating System Runtime API Statistics:\n",
            "\n",
            " Time (%)  Total Time (ns)  Num Calls  Avg (ns)  Med (ns)  Min (ns)  Max (ns)  StdDev (ns)   Name \n",
            " --------  ---------------  ---------  --------  --------  --------  --------  -----------  ------\n",
            "     96.5          157,769         24   6,573.7   4,284.5     3,882    47,951      8,880.9  putc  \n",
            "      3.5            5,677          1   5,677.0   5,677.0     5,677     5,677          0.0  fwrite\n",
            "\n",
            "[5/8] Executing 'cudaapisum' stats report\n",
            "SKIPPED: /home/source_code/lab6/jacobi_step1.sqlite does not contain CUDA trace data.\n",
            "[6/8] Executing 'gpukernsum' stats report\n",
            "SKIPPED: /home/source_code/lab6/jacobi_step1.sqlite does not contain CUDA kernel data.\n",
            "[7/8] Executing 'gpumemtimesum' stats report\n",
            "SKIPPED: /home/source_code/lab6/jacobi_step1.sqlite does not contain GPU memory data.\n",
            "[8/8] Executing 'gpumemsizesum' stats report\n",
            "SKIPPED: /home/source_code/lab6/jacobi_step1.sqlite does not contain GPU memory data.\n",
            "Generated:\n",
            "    /home/source_code/lab6/jacobi_step1.nsys-rep\n",
            "    /home/source_code/lab6/jacobi_step1.sqlite\n"
          ]
        }
      ],
      "source": [
        "!cd /home/source_code/lab6 && make jacobi_step1 && nsys profile --stats=true -o jacobi_step1 -f true ./jacobi_step1"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Download the report by running the below cell and open the report via the Nsight Systems UI."
      ],
      "metadata": {
        "id": "kY8ymbzvkLV1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download('/home/source_code/lab6/jacobi_step1.nsys-rep')"
      ],
      "metadata": {
        "id": "wKC4eBJcKQuy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "6cbc2feb-7bc6-45ad-f66a-128313d9bd4f"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_2547ff6f-c98d-41f1-9888-9d0f97ce80e7\", \"jacobi_step1.nsys-rep\", 172571)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "bWxclXoBFupD"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7rOaId9kvIOo"
      },
      "source": [
        "The timeline of the application is as shown below (feel free to hover your mouse over each section to see more detail; for example, the thread state).\n",
        "\n",
        "<!--<img src=\"images/jacobi_1.png\" width=\"90%\">-->\n",
        "<img src=\"https://drive.google.com/uc?export=download&id=1yKoXC__BnIyQpR7qO5-hs-VIALMBmnDF\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_6YdfAb6vIOp"
      },
      "source": [
        "### Step 2: Using Unified Memory\n",
        "\n",
        "[Unified Memory(UM)](https://developer.nvidia.com/blog/unified-memory-cuda-beginners/) is a single memory address space accessible from any processor in a system. It allows applications to allocate data that can be read or written from code running on either CPUs or GPUs. Now, to allocate Unified Memory, we replace calls to `malloc()` with calls to `cudaMallocManaged()` without making any other changes to the rest of the code.\n",
        "\n",
        "\n",
        "**Understand and analyze** the code:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cat /home/source_code/lab6/jacobi_step2.cpp"
      ],
      "metadata": {
        "id": "KdugXBQgaxwE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4bf71397-46b9-4f7b-feff-e55f25972969"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "// Copyright (c) 2022 NVIDIA Corporation.  All rights reserved.\n",
            "\n",
            "#include <iostream>\n",
            "#include <iomanip>\n",
            "#include <cmath>\n",
            "#include <limits>\n",
            "#include <ctime>\n",
            "#include <nvToolsExt.h>\n",
            "\n",
            "#define N 64\n",
            "\n",
            "#define IDX(i, j) ((j) + (i) * N)\n",
            "\n",
            "// error checking macro\n",
            "#define cudaCheckErrors(msg)                                    \\\n",
            "    do {                                                        \\\n",
            "        cudaError_t __err = cudaGetLastError();                 \\\n",
            "        if (__err != cudaSuccess) {                             \\\n",
            "            fprintf(stderr, \"Fatal error: %s (%s at %s:%d)\\n\",  \\\n",
            "                    msg, cudaGetErrorString(__err),             \\\n",
            "                    __FILE__, __LINE__);                        \\\n",
            "            fprintf(stderr, \"*** FAILED - ABORTING\\n\");         \\\n",
            "            exit(1);                                            \\\n",
            "        }                                                       \\\n",
            "    } while (0)\n",
            "\n",
            "void allocate_memory (float** f, float** f_old, float** error) {\n",
            "    cudaMallocManaged(f, N * N * sizeof(float));\n",
            "    cudaMallocManaged(f_old, N * N * sizeof(float));\n",
            "    cudaMallocManaged(error, sizeof(float));\n",
            "    cudaCheckErrors(\"Memory allocation\");\n",
            "}\n",
            "\n",
            "void free_memory (float* f, float* f_old, float* error) {\n",
            "    cudaFree(f);\n",
            "    cudaFree(f_old);\n",
            "    cudaFree(error);\n",
            "    cudaCheckErrors(\"Memory deallocation\");\n",
            "}\n",
            "\n",
            "void initialize_data (float* f) {\n",
            "    // Set up simple sinusoidal boundary conditions\n",
            "    for (int j = 0; j < N; ++j) {\n",
            "        for (int i = 0; i < N; ++i) {\n",
            "\n",
            "            if (i == 0 || i == N-1) {\n",
            "                f[IDX(i,j)] = sin(j * 2 * M_PI / (N - 1));\n",
            "            }\n",
            "            else if (j == 0 || j == N-1) {\n",
            "                f[IDX(i,j)] = sin(i * 2 * M_PI / (N - 1));\n",
            "            }\n",
            "            else {\n",
            "                f[IDX(i,j)] = 0.0f;\n",
            "            }\n",
            "\n",
            "        }\n",
            "    }\n",
            "}\n",
            "\n",
            "void jacobi_step (float* f, float* f_old, float* error) {\n",
            "    for (int j = 1; j <= N-2; ++j) {\n",
            "        for (int i = 1; i <= N-2; ++i) {\n",
            "            f[IDX(i,j)] = 0.25f * (f_old[IDX(i+1,j)] + f_old[IDX(i-1,j)] +\n",
            "                                   f_old[IDX(i,j+1)] + f_old[IDX(i,j-1)]);\n",
            "\n",
            "            float df = f[IDX(i,j)] - f_old[IDX(i,j)];\n",
            "            *error += df * df;\n",
            "        }\n",
            "    }\n",
            "}\n",
            "\n",
            "void swap_data (float* f, float* f_old) {\n",
            "    for (int j = 1; j <= N-2; ++j) {\n",
            "        for (int i = 1; i <= N-2; ++i) {\n",
            "            f_old[IDX(i,j)] = f[IDX(i,j)];\n",
            "        }\n",
            "    }\n",
            "}\n",
            "\n",
            "int main () {\n",
            "    // Begin wall timing\n",
            "    std::clock_t start_time = std::clock();\n",
            "\n",
            "    float* f;\n",
            "    float* f_old;\n",
            "    float* error;\n",
            "\n",
            "    // Reserve space for the scalar field and the \"old\" copy of the data\n",
            "    nvtxRangePush(\"Allocate memory\");\n",
            "    allocate_memory(&f, &f_old, &error);\n",
            "    nvtxRangePop();\n",
            "\n",
            "    // Initialize data (we'll do this on both f and f_old, so that we don't\n",
            "    // have to worry about the boundary points later)\n",
            "    nvtxRangePush(\"Initialize data\");\n",
            "    initialize_data(f);\n",
            "    initialize_data(f_old);\n",
            "    nvtxRangePop();\n",
            "\n",
            "    // Initialize error to a large number\n",
            "    *error = std::numeric_limits<float>::max();\n",
            "    const float tolerance = 1.e-4f;\n",
            "\n",
            "    // Iterate until we're converged (but set a cap on the maximum number of\n",
            "    // iterations to avoid any possible hangs)\n",
            "    const int max_iters = 1000;\n",
            "    int num_iters = 0;\n",
            "\n",
            "    while (*error > tolerance && num_iters < max_iters) {\n",
            "        // Initialize error to zero (we'll add to it the following step)\n",
            "        *error = 0.0f;\n",
            "\n",
            "        // Perform a Jacobi relaxation step\n",
            "        nvtxRangePush(\"Jacobi step\");\n",
            "        jacobi_step(f, f_old, error);\n",
            "        nvtxRangePop();\n",
            "\n",
            "        // Swap the old data and the new data\n",
            "        // We're doing this explicitly for pedagogical purposes, even though\n",
            "        // in this specific application a std::swap would have been OK\n",
            "        nvtxRangePush(\"Swap data\");\n",
            "        swap_data(f, f_old);\n",
            "        nvtxRangePop();\n",
            "\n",
            "        // Normalize the L2-norm of the error by the number of data points\n",
            "        // and then take the square root\n",
            "        *error = std::sqrt(*error / (N * N));\n",
            "\n",
            "        // Periodically print out the current error\n",
            "        if (num_iters % 25 == 0) {\n",
            "            std::cout << \"Error after iteration \" << num_iters << \" = \" << *error << std::endl;\n",
            "        }\n",
            "\n",
            "        // Increment the iteration count\n",
            "        ++num_iters;\n",
            "    }\n",
            "\n",
            "    // If we took fewer than max_iters steps and the error is below the tolerance,\n",
            "    // we succeeded. Otherwise, we failed.\n",
            "\n",
            "    if (*error <= tolerance && num_iters < max_iters) {\n",
            "        std::cout << \"Success!\" << std::endl;\n",
            "    }\n",
            "    else {\n",
            "        std::cout << \"Failure!\" << std::endl;\n",
            "        return -1;\n",
            "    }\n",
            "\n",
            "    // Clean up memory allocations\n",
            "    nvtxRangePush(\"Free memory\");\n",
            "    free_memory(f, f_old, error);\n",
            "    nvtxRangePop();\n",
            "\n",
            "    // End wall timing\n",
            "    double duration = (std::clock() - start_time) / (double) CLOCKS_PER_SEC;\n",
            "    std::cout << \"Run time = \" << std::setprecision(4) << duration << \" seconds\" << std::endl;\n",
            "\n",
            "    return 0;\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, compile and profile the code."
      ],
      "metadata": {
        "id": "vHXNAz0Ka2Sy"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "97qL5r8wvIOq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ce8dedfc-3384-4456-fba6-1447e451ebbf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc -o jacobi_step2 -x cu -lnvToolsExt -lineinfo jacobi_step2.cpp\n",
            "Warning: LBR backtrace method is not supported on this platform. DWARF backtrace method will be used.\n",
            "Error after iteration 0 = 0.0438475\n",
            "Error after iteration 25 = 0.0032022\n",
            "Error after iteration 50 = 0.00181223\n",
            "Error after iteration 75 = 0.00126184\n",
            "Error after iteration 100 = 0.000957702\n",
            "Error after iteration 125 = 0.000762262\n",
            "Error after iteration 150 = 0.000625323\n",
            "Error after iteration 175 = 0.000523902\n",
            "Error after iteration 200 = 0.000445912\n",
            "Error after iteration 225 = 0.000384343\n",
            "Error after iteration 250 = 0.000334796\n",
            "Error after iteration 275 = 0.000294325\n",
            "Error after iteration 300 = 0.000260843\n",
            "Error after iteration 325 = 0.00023282\n",
            "Error after iteration 350 = 0.000209104\n",
            "Error after iteration 375 = 0.000188812\n",
            "Error after iteration 400 = 0.00017127\n",
            "Error after iteration 425 = 0.000155952\n",
            "Error after iteration 450 = 0.000142454\n",
            "Error after iteration 475 = 0.000130462\n",
            "Error after iteration 500 = 0.000119732\n",
            "Error after iteration 525 = 0.000110069\n",
            "Error after iteration 550 = 0.000101323\n",
            "Success!\n",
            "Run time = 0.5275 seconds\n",
            "Generating '/tmp/nsys-report-7b2e.qdstrm'\n",
            "[1/8] [========================100%] jacobi_step2.nsys-rep\n",
            "Importer error status: Importation succeeded with non-fatal errors.\n",
            "**** Analysis failed with:\n",
            "Status: TargetProfilingFailed\n",
            "Props {\n",
            "  Items {\n",
            "    Type: DeviceId\n",
            "    Value: \"Local (CLI)\"\n",
            "  }\n",
            "}\n",
            "Error {\n",
            "  Type: RuntimeError\n",
            "  SubError {\n",
            "    Type: ProcessEventsError\n",
            "    Props {\n",
            "      Items {\n",
            "        Type: ErrorText\n",
            "        Value: \"/build/agent/work/20a3cfcd1c25021d/QuadD/Host/Analysis/Modules/TraceProcessEvent.cpp(45): Throw in function const string& {anonymous}::GetCudaCallbackName(bool, uint32_t, const QuadDAnalysis::MoreInjection&)\\nDynamic exception type: boost::exception_detail::clone_impl<QuadDCommon::InvalidArgumentException>\\nstd::exception::what: InvalidArgumentException\\n[QuadDCommon::tag_message*] = Unknown driver API function index: 673\\n\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n",
            "\n",
            "**** Errors occurred while processing the raw events. ****\n",
            "**** Please see the Diagnostics Summary page after opening the report file in GUI. ****\n",
            "[2/8] [========================100%] jacobi_step2.sqlite\n",
            "[3/8] Executing 'nvtxsum' stats report\n",
            "\n",
            "NVTX Range Statistics:\n",
            "\n",
            " Time (%)  Total Time (ns)  Instances    Avg (ns)       Med (ns)      Min (ns)     Max (ns)    StdDev (ns)   Style        Range     \n",
            " --------  ---------------  ---------  -------------  -------------  -----------  -----------  -----------  -------  ---------------\n",
            "     95.9      657,186,173          1  657,186,173.0  657,186,173.0  657,186,173  657,186,173          0.0  PushPop  Allocate memory\n",
            "      3.2       21,594,855        555       38,909.6       35,402.0       33,038      631,317     26,321.0  PushPop  Jacobi step    \n",
            "      0.9        6,262,947        555       11,284.6       10,303.0       10,071       39,335      2,731.8  PushPop  Swap data      \n",
            "      0.0          155,384          1      155,384.0      155,384.0      155,384      155,384          0.0  PushPop  Initialize data\n",
            "      0.0          119,889          1      119,889.0      119,889.0      119,889      119,889          0.0  PushPop  Free memory    \n",
            "\n",
            "[4/8] Executing 'osrtsum' stats report\n",
            "\n",
            "Operating System Runtime API Statistics:\n",
            "\n",
            " Time (%)  Total Time (ns)  Num Calls    Avg (ns)       Med (ns)      Min (ns)     Max (ns)     StdDev (ns)        Name     \n",
            " --------  ---------------  ---------  -------------  -------------  -----------  -----------  -------------  --------------\n",
            "     67.1      973,703,111          2  486,851,555.5  486,851,555.5  283,597,911  690,105,200  287,444,060.7  sem_wait      \n",
            "     24.9      360,893,879         20   18,044,694.0    9,753,651.5        4,163  100,130,368   28,206,049.1  poll          \n",
            "      4.7       67,571,947        510      132,494.0       14,928.5        1,017   18,879,729      982,116.0  ioctl         \n",
            "      3.2       45,855,177         15    3,057,011.8       76,000.0       30,897   20,612,334    6,581,134.2  sem_timedwait \n",
            "      0.1        1,413,227         31       45,588.0        8,186.0        6,372      912,223      161,461.2  mmap64        \n",
            "      0.0          485,353         49        9,905.2        9,274.0        2,385       27,288        3,869.7  open64        \n",
            "      0.0          384,274         57        6,741.6        4,095.0        1,709       60,872        9,044.8  fopen         \n",
            "      0.0          201,564         21        9,598.3        5,819.0        1,159       47,622       11,101.4  mmap          \n",
            "      0.0          179,820          4       44,955.0       44,050.5       39,036       52,683        6,009.3  pthread_create\n",
            "      0.0          143,593         25        5,743.7        4,437.0        3,766       16,650        3,559.8  putc          \n",
            "      0.0          103,815          5       20,763.0       22,498.0        9,058       35,310       11,547.7  fgets         \n",
            "      0.0           74,877         37        2,023.7        1,789.0        1,022        6,032        1,007.3  fclose        \n",
            "      0.0           53,587         11        4,871.5        4,544.0        1,372        9,403        2,078.5  write         \n",
            "      0.0           40,526          5        8,105.2        8,044.0        3,002       14,671        4,221.8  open          \n",
            "      0.0           34,100          6        5,683.3        2,887.5        2,003       17,958        6,205.9  fread         \n",
            "      0.0           33,383         10        3,338.3        2,658.5        1,408        8,620        2,307.9  read          \n",
            "      0.0           25,370          7        3,624.3        4,005.0        1,682        5,488        1,433.8  munmap        \n",
            "      0.0           23,165          2       11,582.5       11,582.5        8,867       14,298        3,840.3  socket        \n",
            "      0.0           13,731          5        2,746.2        1,513.0        1,003        5,909        2,182.7  fcntl         \n",
            "      0.0           11,579          1       11,579.0       11,579.0       11,579       11,579            0.0  fflush        \n",
            "      0.0            9,187          1        9,187.0        9,187.0        9,187        9,187            0.0  pipe2         \n",
            "      0.0            8,991          1        8,991.0        8,991.0        8,991        8,991            0.0  connect       \n",
            "      0.0            8,601          2        4,300.5        4,300.5        3,310        5,291        1,400.8  fwrite        \n",
            "      0.0            6,505          1        6,505.0        6,505.0        6,505        6,505            0.0  fopen64       \n",
            "      0.0            1,674          1        1,674.0        1,674.0        1,674        1,674            0.0  bind          \n",
            "      0.0            1,147          1        1,147.0        1,147.0        1,147        1,147            0.0  listen        \n",
            "\n",
            "[5/8] Executing 'cudaapisum' stats report\n",
            "SKIPPED: /home/source_code/lab6/jacobi_step2.sqlite does not contain CUDA trace data.\n",
            "[6/8] Executing 'gpukernsum' stats report\n",
            "SKIPPED: /home/source_code/lab6/jacobi_step2.sqlite does not contain CUDA kernel data.\n",
            "[7/8] Executing 'gpumemtimesum' stats report\n",
            "SKIPPED: /home/source_code/lab6/jacobi_step2.sqlite does not contain GPU memory data.\n",
            "[8/8] Executing 'gpumemsizesum' stats report\n",
            "SKIPPED: /home/source_code/lab6/jacobi_step2.sqlite does not contain GPU memory data.\n",
            "Generated:\n",
            "    /home/source_code/lab6/jacobi_step2.qdstrm\n",
            "    /home/source_code/lab6/jacobi_step2.nsys-rep\n",
            "    /home/source_code/lab6/jacobi_step2.sqlite\n"
          ]
        }
      ],
      "source": [
        "!cd /home/source_code/lab6 && make jacobi_step2 && nsys profile --stats=true -o jacobi_step2 -f true ./jacobi_step2"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Download the report by running the below cell and open the report via the Nsight Systems user interface (UI)."
      ],
      "metadata": {
        "id": "Of-5vH4Hkewl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download('/home/source_code/lab6/jacobi_step2.nsys-rep')"
      ],
      "metadata": {
        "id": "uDM1fig7keOV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "d3221263-ab5c-4c30-bd84-6667901b9dea"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_dcd54c44-3f9f-4cc9-9e1e-6fc1d0f84743\", \"jacobi_step2.nsys-rep\", 219422)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kcff9uGzvIOq"
      },
      "source": [
        "The timeline of the application is shown below.\n",
        "\n",
        "<!--<img src=\"images/jacobi_2.png\" width=\"90%\">-->\n",
        "<img src=\"https://drive.google.com/uc?export=download&id=185mvFtRq6dGl5Ijw6UIFzLLNBLPlhjpT\">\n",
        "\n",
        "\n",
        "The application runs much longer than before. As you can see from the profiler report, there is a cost of initializing CUDA that can be high. In this example, this cost is much higher than the actual calculation time.\n",
        "\n",
        "<!--<img src=\"images/jacobi_2_.png\" width=\"90%\">-->\n",
        "<img src=\"https://drive.google.com/uc?export=download&id=1xVH8j9RAaFbIBs7xOnByYonn5jpMymMj\">\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AinngAGXvIOr"
      },
      "source": [
        "### Step 3: Make the Problem Bigger\n",
        "\n",
        "If we try to reduce the cost of computation and add fast kernels, it will still be slower than the CPU-only version (without UM). Like the previous lab, we simply need to make the problem bigger by either adding more particles/elements or increasing the iteration count. In this example, we increase the grid points `N` which achieves a finer spatial resolution and is more accurate. This will make the Jacobi relaxation step a big chunk of the total application runtime.\n",
        "\n",
        "\n",
        "**Understand and analyze** the code:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cat /home/source_code/lab6/jacobi_step3.cpp"
      ],
      "metadata": {
        "id": "64F_sjCEbqCH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8cbc0515-985f-4000-b8e7-71afe0e3d65e"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "// Copyright (c) 2022 NVIDIA Corporation.  All rights reserved.\n",
            "\n",
            "#include <iostream>\n",
            "#include <iomanip>\n",
            "#include <cmath>\n",
            "#include <limits>\n",
            "#include <ctime>\n",
            "#include <nvToolsExt.h>\n",
            "\n",
            "#define N 2048\n",
            "\n",
            "#define IDX(i, j) ((j) + (i) * N)\n",
            "\n",
            "// error checking macro\n",
            "#define cudaCheckErrors(msg)                                    \\\n",
            "    do {                                                        \\\n",
            "        cudaError_t __err = cudaGetLastError();                 \\\n",
            "        if (__err != cudaSuccess) {                             \\\n",
            "            fprintf(stderr, \"Fatal error: %s (%s at %s:%d)\\n\",  \\\n",
            "                    msg, cudaGetErrorString(__err),             \\\n",
            "                    __FILE__, __LINE__);                        \\\n",
            "            fprintf(stderr, \"*** FAILED - ABORTING\\n\");         \\\n",
            "            exit(1);                                            \\\n",
            "        }                                                       \\\n",
            "    } while (0)\n",
            "\n",
            "void allocate_memory (float** f, float** f_old, float** error) {\n",
            "    cudaMallocManaged(f, N * N * sizeof(float));\n",
            "    cudaMallocManaged(f_old, N * N * sizeof(float));\n",
            "    cudaMallocManaged(error, sizeof(float));\n",
            "    cudaCheckErrors(\"Memory allocation\");\n",
            "}\n",
            "\n",
            "void free_memory (float* f, float* f_old, float* error) {\n",
            "    cudaFree(f);\n",
            "    cudaFree(f_old);\n",
            "    cudaFree(error);\n",
            "    cudaCheckErrors(\"Memory deallocation\");\n",
            "}\n",
            "\n",
            "void initialize_data (float* f) {\n",
            "    // Set up simple sinusoidal boundary conditions\n",
            "    for (int j = 0; j < N; ++j) {\n",
            "        for (int i = 0; i < N; ++i) {\n",
            "\n",
            "            if (i == 0 || i == N-1) {\n",
            "                f[IDX(i,j)] = sin(j * 2 * M_PI / (N - 1));\n",
            "            }\n",
            "            else if (j == 0 || j == N-1) {\n",
            "                f[IDX(i,j)] = sin(i * 2 * M_PI / (N - 1));\n",
            "            }\n",
            "            else {\n",
            "                f[IDX(i,j)] = 0.0f;\n",
            "            }\n",
            "\n",
            "        }\n",
            "    }\n",
            "}\n",
            "\n",
            "void jacobi_step (float* f, float* f_old, float* error) {\n",
            "    for (int j = 1; j <= N-2; ++j) {\n",
            "        for (int i = 1; i <= N-2; ++i) {\n",
            "            f[IDX(i,j)] = 0.25f * (f_old[IDX(i+1,j)] + f_old[IDX(i-1,j)] +\n",
            "                                   f_old[IDX(i,j+1)] + f_old[IDX(i,j-1)]);\n",
            "\n",
            "            float df = f[IDX(i,j)] - f_old[IDX(i,j)];\n",
            "            *error += df * df;\n",
            "        }\n",
            "    }\n",
            "}\n",
            "\n",
            "void swap_data (float* f, float* f_old) {\n",
            "    for (int j = 1; j <= N-2; ++j) {\n",
            "        for (int i = 1; i <= N-2; ++i) {\n",
            "            f_old[IDX(i,j)] = f[IDX(i,j)];\n",
            "        }\n",
            "    }\n",
            "}\n",
            "\n",
            "int main () {\n",
            "    // Begin wall timing\n",
            "    std::clock_t start_time = std::clock();\n",
            "\n",
            "    float* f;\n",
            "    float* f_old;\n",
            "    float* error;\n",
            "\n",
            "    // Reserve space for the scalar field and the \"old\" copy of the data\n",
            "    nvtxRangePush(\"Allocate memory\");\n",
            "    allocate_memory(&f, &f_old, &error);\n",
            "    nvtxRangePop();\n",
            "\n",
            "    // Initialize data (we'll do this on both f and f_old, so that we don't\n",
            "    // have to worry about the boundary points later)\n",
            "    nvtxRangePush(\"Initialize data\");\n",
            "    initialize_data(f);\n",
            "    initialize_data(f_old);\n",
            "    nvtxRangePop();\n",
            "\n",
            "    // Initialize error to a large number\n",
            "    *error = std::numeric_limits<float>::max();\n",
            "    const float tolerance = 1.e-4f;\n",
            "\n",
            "    // Iterate until we're converged (but set a cap on the maximum number of\n",
            "    // iterations to avoid any possible hangs)\n",
            "    const int max_iters = 1000;\n",
            "    int num_iters = 0;\n",
            "\n",
            "    while (*error > tolerance && num_iters < max_iters) {\n",
            "        // Initialize error to zero (we'll add to it the following step)\n",
            "        *error = 0.0f;\n",
            "\n",
            "        // Perform a Jacobi relaxation step\n",
            "        nvtxRangePush(\"Jacobi step\");\n",
            "        jacobi_step(f, f_old, error);\n",
            "        nvtxRangePop();\n",
            "\n",
            "        // Swap the old data and the new data\n",
            "        // We're doing this explicitly for pedagogical purposes, even though\n",
            "        // in this specific application a std::swap would have been OK\n",
            "        nvtxRangePush(\"Swap data\");\n",
            "        swap_data(f, f_old);\n",
            "        nvtxRangePop();\n",
            "\n",
            "        // Normalize the L2-norm of the error by the number of data points\n",
            "        // and then take the square root\n",
            "        *error = std::sqrt(*error / (N * N));\n",
            "\n",
            "        // Periodically print out the current error\n",
            "        if (num_iters % 25 == 0) {\n",
            "            std::cout << \"Error after iteration \" << num_iters << \" = \" << *error << std::endl;\n",
            "        }\n",
            "\n",
            "        // Increment the iteration count\n",
            "        ++num_iters;\n",
            "    }\n",
            "\n",
            "    // If we took fewer than max_iters steps and the error is below the tolerance,\n",
            "    // we succeeded. Otherwise, we failed.\n",
            "\n",
            "    if (*error <= tolerance && num_iters < max_iters) {\n",
            "        std::cout << \"Success!\" << std::endl;\n",
            "    }\n",
            "    else {\n",
            "        std::cout << \"Failure!\" << std::endl;\n",
            "        return -1;\n",
            "    }\n",
            "\n",
            "    // Clean up memory allocations\n",
            "    nvtxRangePush(\"Free memory\");\n",
            "    free_memory(f, f_old, error);\n",
            "    nvtxRangePop();\n",
            "\n",
            "    // End wall timing\n",
            "    double duration = (std::clock() - start_time) / (double) CLOCKS_PER_SEC;\n",
            "    std::cout << \"Run time = \" << std::setprecision(4) << duration << \" seconds\" << std::endl;\n",
            "\n",
            "    return 0;\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, compile and profile the code."
      ],
      "metadata": {
        "id": "WOlGR5kbbvre"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "ryQohfGaHOTW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "wI7qg5wzvIOr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c32c70dd-698b-4a2b-f8ba-e710a6fd9baa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc -o jacobi_step3 -x cu -lnvToolsExt -lineinfo jacobi_step3.cpp\n",
            "Warning: LBR backtrace method is not supported on this platform. DWARF backtrace method will be used.\n",
            "Error after iteration 0 = 0.00781058\n",
            "Error after iteration 25 = 0.000608073\n",
            "Error after iteration 50 = 0.000366189\n",
            "Error after iteration 75 = 0.000271313\n",
            "Error after iteration 100 = 0.00021912\n",
            "Error after iteration 125 = 0.000185581\n",
            "Error after iteration 150 = 0.000161997\n",
            "Error after iteration 175 = 0.000144382\n",
            "Error after iteration 200 = 0.000130678\n",
            "Error after iteration 225 = 0.000119665\n",
            "Error after iteration 250 = 0.000110599\n",
            "Error after iteration 275 = 0.000102984\n",
            "Success!\n",
            "Run time = 72.36 seconds\n",
            "Generating '/tmp/nsys-report-120e.qdstrm'\n",
            "[1/8] [========================100%] jacobi_step3.nsys-rep\n",
            "Importer error status: Importation succeeded with non-fatal errors.\n",
            "**** Analysis failed with:\n",
            "Status: TargetProfilingFailed\n",
            "Props {\n",
            "  Items {\n",
            "    Type: DeviceId\n",
            "    Value: \"Local (CLI)\"\n",
            "  }\n",
            "}\n",
            "Error {\n",
            "  Type: RuntimeError\n",
            "  SubError {\n",
            "    Type: ProcessEventsError\n",
            "    Props {\n",
            "      Items {\n",
            "        Type: ErrorText\n",
            "        Value: \"/build/agent/work/20a3cfcd1c25021d/QuadD/Host/Analysis/Modules/TraceProcessEvent.cpp(45): Throw in function const string& {anonymous}::GetCudaCallbackName(bool, uint32_t, const QuadDAnalysis::MoreInjection&)\\nDynamic exception type: boost::exception_detail::clone_impl<QuadDCommon::InvalidArgumentException>\\nstd::exception::what: InvalidArgumentException\\n[QuadDCommon::tag_message*] = Unknown driver API function index: 673\\n\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n",
            "\n",
            "**** Errors occurred while processing the raw events. ****\n",
            "**** Please see the Diagnostics Summary page after opening the report file in GUI. ****\n",
            "[2/8] [========================100%] jacobi_step3.sqlite\n",
            "[3/8] Executing 'nvtxsum' stats report\n",
            "\n",
            "NVTX Range Statistics:\n",
            "\n",
            " Time (%)  Total Time (ns)  Instances    Avg (ns)       Med (ns)      Min (ns)     Max (ns)    StdDev (ns)    Style        Range     \n",
            " --------  ---------------  ---------  -------------  -------------  -----------  -----------  ------------  -------  ---------------\n",
            "     53.2   38,499,158,802        288  133,677,634.7  121,893,161.5  100,083,817  271,599,173  34,556,015.1  PushPop  Jacobi step    \n",
            "     45.7   33,121,860,994        288  115,006,461.8  112,873,193.5   96,725,019  166,289,769  12,575,548.9  PushPop  Swap data      \n",
            "      0.8      571,868,250          1  571,868,250.0  571,868,250.0  571,868,250  571,868,250           0.0  PushPop  Allocate memory\n",
            "      0.3      227,787,894          1  227,787,894.0  227,787,894.0  227,787,894  227,787,894           0.0  PushPop  Initialize data\n",
            "      0.0        1,504,467          1    1,504,467.0    1,504,467.0    1,504,467    1,504,467           0.0  PushPop  Free memory    \n",
            "\n",
            "[4/8] Executing 'osrtsum' stats report\n",
            "\n",
            "Operating System Runtime API Statistics:\n",
            "\n",
            " Time (%)  Total Time (ns)  Num Calls      Avg (ns)          Med (ns)       Min (ns)       Max (ns)       StdDev (ns)          Name     \n",
            " --------  ---------------  ---------  ----------------  ----------------  -----------  --------------  ----------------  --------------\n",
            "     60.7  131,371,664,164      6,588      19,941,054.1      10,081,271.0        2,793     107,606,556      28,076,343.1  poll          \n",
            "     33.5   72,629,898,157          2  36,314,949,078.5  36,314,949,078.5  185,278,224  72,444,619,933  51,095,070,526.5  sem_wait      \n",
            "      5.7   12,416,845,746      5,858       2,119,639.1       2,075,842.5    2,009,591      21,862,948         486,653.1  sem_timedwait \n",
            "      0.0       87,230,889        522         167,109.0          19,832.0        1,029      23,475,238       1,236,321.4  ioctl         \n",
            "      0.0        2,097,233         31          67,652.7           9,590.0        7,451       1,399,489         248,181.5  mmap64        \n",
            "      0.0        1,570,300         26          60,396.2          10,757.5        1,476         742,302         174,917.4  mmap          \n",
            "      0.0        1,405,316         11         127,756.0          27,792.0        1,243       1,180,126         349,346.6  write         \n",
            "      0.0          614,779         14          43,912.8          49,996.5        8,776          75,871          23,763.1  putc          \n",
            "      0.0          608,783         54          11,273.8           5,715.0        1,650         218,056          29,577.7  fopen         \n",
            "      0.0          598,827         49          12,221.0          10,811.0        4,522          35,516           5,224.1  open64        \n",
            "      0.0          210,692          4          52,673.0          53,624.0       35,864          67,580          13,111.0  pthread_create\n",
            "      0.0          111,396          5          22,279.2          16,545.0        8,646          57,735          20,346.7  fgets         \n",
            "      0.0           95,036         43           2,210.1           2,042.0        1,407           4,313             617.1  fclose        \n",
            "      0.0           43,699          5           8,739.8           6,241.0        5,809          13,535           3,735.4  open          \n",
            "      0.0           42,100         10           4,210.0           3,970.0        1,334           9,614           2,191.6  munmap        \n",
            "      0.0           33,378         13           2,567.5           1,816.0        1,430          11,466           2,683.2  fwrite        \n",
            "      0.0           30,553         11           2,777.5           1,482.0        1,025          11,406           3,034.8  read          \n",
            "      0.0           27,780          2          13,890.0          13,890.0        9,935          17,845           5,593.2  socket        \n",
            "      0.0           26,519          6           4,419.8           3,272.0        2,084           8,912           2,611.3  fread         \n",
            "      0.0           11,410          1          11,410.0          11,410.0       11,410          11,410               0.0  connect       \n",
            "      0.0            8,574          1           8,574.0           8,574.0        8,574           8,574               0.0  pipe2         \n",
            "      0.0            7,364          2           3,682.0           3,682.0        1,341           6,023           3,310.7  fcntl         \n",
            "      0.0            7,068          1           7,068.0           7,068.0        7,068           7,068               0.0  fopen64       \n",
            "      0.0            1,888          1           1,888.0           1,888.0        1,888           1,888               0.0  bind          \n",
            "      0.0            1,141          1           1,141.0           1,141.0        1,141           1,141               0.0  listen        \n",
            "\n",
            "[5/8] Executing 'cudaapisum' stats report\n",
            "SKIPPED: /home/source_code/lab6/jacobi_step3.sqlite does not contain CUDA trace data.\n",
            "[6/8] Executing 'gpukernsum' stats report\n",
            "SKIPPED: /home/source_code/lab6/jacobi_step3.sqlite does not contain CUDA kernel data.\n",
            "[7/8] Executing 'gpumemtimesum' stats report\n",
            "SKIPPED: /home/source_code/lab6/jacobi_step3.sqlite does not contain GPU memory data.\n",
            "[8/8] Executing 'gpumemsizesum' stats report\n",
            "SKIPPED: /home/source_code/lab6/jacobi_step3.sqlite does not contain GPU memory data.\n",
            "Generated:\n",
            "    /home/source_code/lab6/jacobi_step3.qdstrm\n",
            "    /home/source_code/lab6/jacobi_step3.nsys-rep\n",
            "    /home/source_code/lab6/jacobi_step3.sqlite\n"
          ]
        }
      ],
      "source": [
        "!cd /home/source_code/lab6 && make jacobi_step3 && nsys profile --stats=true -o jacobi_step3 -f true ./jacobi_step3"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Download the report by running the below cell and open the report via the Nsight Systems user interface (UI)."
      ],
      "metadata": {
        "id": "nkFqM77NmhgB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download('/home/source_code/lab6/jacobi_step3.nsys-rep')"
      ],
      "metadata": {
        "id": "yGewhbimmh7o",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "539b099a-c5ae-449c-be8a-6f770e5285e4"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_2c2d77b2-9146-4f8b-99ec-3f55ddefc1ce\", \"jacobi_step3.nsys-rep\", 5104828)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rvhHMickvIOs"
      },
      "source": [
        "\n",
        "\n",
        "With a close look at the \"Timeline View\", we can see that the Jacobi relaxation step is now a big portion of the total application runtime.\n",
        "\n",
        "<!--<img src=\"images/jacobi_3.png\" width=\"90%\">-->\n",
        "<img src=\"https://drive.google.com/uc?export=download&id=14UwH05ktYoGU-eWsgWKyEtUre4vHC90u\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f6gHAIc-vIOs"
      },
      "source": [
        "You can also see the most expensive portion of the application from the profiler report. Right-click on the NVTX row from the \"Timline View\", then choose \"Show in Events View\". From the box at the bottom, you can sort all the ranges by duration. Now, you can see the `jacobi_step()` (Jacobi relaxation step) is the most compute expensive part of the code.\n",
        "\n",
        "<!--<img src=\"images/jacobi_3_event.png\" width=\"90%\">-->\n",
        "<img src=\"https://drive.google.com/uc?export=download&id=1K512a45AABoS-HahiMRrHSJJtC4uk2Pu\">\n",
        "\n",
        "\n",
        "### Step 4: Port the `jacobi_step` Kernel to GPU using CUDA\n",
        "\n",
        "We convert the `jacobi_step()` to a CUDA kernel, parallelizing over the inner and outer loop using a 2D threadblock of size `32x32`. Except for the `error`, each part can be updated independently `atomicadd()` to perform that.\n",
        "\n",
        "**Understand and analyze** the code:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cat /home/source_code/lab6/jacobi_step4.cpp"
      ],
      "metadata": {
        "id": "vhnkEW10cOkA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, compile and profile the code."
      ],
      "metadata": {
        "id": "aabMwQ4_cPwf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "hOt7IyGbvIOt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6e20448a-2141-4e09-a97d-57d8c0af1df2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "make: 'jacobi_step4' is up to date.\n",
            "Warning: LBR backtrace method is not supported on this platform. DWARF backtrace method will be used.\n",
            "Error after iteration 0 = 0.00781058\n",
            "Error after iteration 25 = 0.000608074\n",
            "Error after iteration 50 = 0.000366187\n",
            "Error after iteration 75 = 0.000271309\n",
            "Error after iteration 100 = 0.000219121\n",
            "Error after iteration 125 = 0.000185579\n",
            "Error after iteration 150 = 0.000161997\n",
            "Error after iteration 175 = 0.000144383\n",
            "Error after iteration 200 = 0.000130679\n",
            "Error after iteration 225 = 0.000119665\n",
            "Error after iteration 250 = 0.0001106\n",
            "Error after iteration 275 = 0.000102985\n",
            "Success!\n",
            "Run time = 46.07 seconds\n",
            "Generating '/tmp/nsys-report-bb6c.qdstrm'\n",
            "[1/8] [========================100%] jacobi_step4.nsys-rep\n",
            "Importer error status: Importation succeeded with non-fatal errors.\n",
            "**** Analysis failed with:\n",
            "Status: TargetProfilingFailed\n",
            "Props {\n",
            "  Items {\n",
            "    Type: DeviceId\n",
            "    Value: \"Local (CLI)\"\n",
            "  }\n",
            "}\n",
            "Error {\n",
            "  Type: RuntimeError\n",
            "  SubError {\n",
            "    Type: ProcessEventsError\n",
            "    Props {\n",
            "      Items {\n",
            "        Type: ErrorText\n",
            "        Value: \"/build/agent/work/20a3cfcd1c25021d/QuadD/Host/Analysis/Modules/TraceProcessEvent.cpp(45): Throw in function const string& {anonymous}::GetCudaCallbackName(bool, uint32_t, const QuadDAnalysis::MoreInjection&)\\nDynamic exception type: boost::exception_detail::clone_impl<QuadDCommon::InvalidArgumentException>\\nstd::exception::what: InvalidArgumentException\\n[QuadDCommon::tag_message*] = Unknown driver API function index: 673\\n\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n",
            "\n",
            "**** Errors occurred while processing the raw events. ****\n",
            "**** Please see the Diagnostics Summary page after opening the report file in GUI. ****\n",
            "[2/8] [========================100%] jacobi_step4.sqlite\n",
            "[3/8] Executing 'nvtxsum' stats report\n",
            "\n",
            "NVTX Range Statistics:\n",
            "\n",
            " Time (%)  Total Time (ns)  Instances    Avg (ns)       Med (ns)      Min (ns)     Max (ns)    StdDev (ns)    Style        Range     \n",
            " --------  ---------------  ---------  -------------  -------------  -----------  -----------  ------------  -------  ---------------\n",
            "     80.5   37,339,417,654        288  129,650,755.7  125,981,074.0  106,279,433  291,304,583  18,980,770.4  PushPop  Swap data      \n",
            "     18.2    8,450,738,801        288   29,342,843.1   27,873,937.0   25,936,314   42,104,266   3,243,912.1  PushPop  Jacobi step    \n",
            "      0.9      434,987,980          1  434,987,980.0  434,987,980.0  434,987,980  434,987,980           0.0  PushPop  Allocate memory\n",
            "      0.4      164,323,970          1  164,323,970.0  164,323,970.0  164,323,970  164,323,970           0.0  PushPop  Initialize data\n",
            "      0.0        4,180,365          1    4,180,365.0    4,180,365.0    4,180,365    4,180,365           0.0  PushPop  Free memory    \n",
            "\n",
            "[4/8] Executing 'osrtsum' stats report\n",
            "\n",
            "Operating System Runtime API Statistics:\n",
            "\n",
            " Time (%)  Total Time (ns)  Num Calls     Avg (ns)         Med (ns)      Min (ns)     Max (ns)       StdDev (ns)           Name       \n",
            " --------  ---------------  ---------  ---------------  ---------------  ---------  -------------  ---------------  ------------------\n",
            "     60.7   83,694,295,328      4,229     19,790,564.0     10,079,146.0      1,812    108,034,555     28,122,130.1  poll              \n",
            "     33.3   45,909,506,722         13  3,531,500,517.1  4,343,348,851.0  3,642,129  5,116,011,284  1,988,532,829.3  sem_wait          \n",
            "      6.0    8,207,521,619      3,762      2,181,691.0      2,073,600.0     48,152     20,775,925        769,972.6  sem_timedwait     \n",
            "      0.1       72,139,644        523        137,934.3         13,897.0      1,007     18,189,334        972,001.7  ioctl             \n",
            "      0.0        4,133,546         26        158,982.5          7,798.0      1,195      2,043,778        525,183.4  mmap              \n",
            "      0.0        1,544,820         31         49,832.9          7,762.0      4,980        969,056        171,658.0  mmap64            \n",
            "      0.0          485,786         49          9,914.0          9,307.0      2,401         20,121          3,376.9  open64            \n",
            "      0.0          374,265         14         26,733.2         13,553.0      8,231         58,766         22,120.9  putc              \n",
            "      0.0          263,838         54          4,885.9          3,950.0      1,568         18,017          3,404.0  fopen             \n",
            "      0.0          218,460          4         54,615.0         53,461.0     43,180         68,358         10,390.9  pthread_create    \n",
            "      0.0          127,564          1        127,564.0        127,564.0    127,564        127,564              0.0  pthread_mutex_lock\n",
            "      0.0          126,140         11         11,467.3          6,934.0      1,182         31,183          9,995.2  write             \n",
            "      0.0           80,972          6         13,495.3          9,584.0      5,493         35,341         11,334.1  fgets             \n",
            "      0.0           62,555         36          1,737.6          1,598.0      1,025          5,013            774.7  fclose            \n",
            "      0.0           36,114         13          2,778.0          1,970.0      1,802         10,591          2,384.9  fwrite            \n",
            "      0.0           32,687          5          6,537.4          5,022.0      3,382         10,240          3,111.1  open              \n",
            "      0.0           32,032         10          3,203.2          2,913.0      1,421          5,158          1,368.3  munmap            \n",
            "      0.0           27,684          2         13,842.0         13,842.0      9,450         18,234          6,211.2  socket            \n",
            "      0.0           23,364          7          3,337.7          2,532.0      1,986          5,038          1,333.3  fread             \n",
            "      0.0           16,368          8          2,046.0          2,105.5      1,089          2,776            603.6  read              \n",
            "      0.0           13,553          1         13,553.0         13,553.0     13,553         13,553              0.0  fopen64           \n",
            "      0.0           13,505          1         13,505.0         13,505.0     13,505         13,505              0.0  connect           \n",
            "      0.0            7,734          2          3,867.0          3,867.0      1,562          6,172          3,259.8  fcntl             \n",
            "      0.0            7,340          1          7,340.0          7,340.0      7,340          7,340              0.0  pipe2             \n",
            "      0.0            2,197          1          2,197.0          2,197.0      2,197          2,197              0.0  fflush            \n",
            "      0.0            1,955          1          1,955.0          1,955.0      1,955          1,955              0.0  bind              \n",
            "      0.0            1,435          1          1,435.0          1,435.0      1,435          1,435              0.0  listen            \n",
            "\n",
            "[5/8] Executing 'cudaapisum' stats report\n",
            "\n",
            "CUDA API Statistics:\n",
            "\n",
            " Time (%)  Total Time (ns)  Num Calls    Avg (ns)      Med (ns)     Min (ns)    Max (ns)   StdDev (ns)          Name         \n",
            " --------  ---------------  ---------  ------------  ------------  ----------  ----------  -----------  ---------------------\n",
            "     99.6    8,340,949,448        286  29,164,158.9  27,766,660.0  22,190,727  42,036,545  3,223,112.2  cudaDeviceSynchronize\n",
            "      0.3       29,192,496        286     102,071.7      58,406.0      45,593   6,190,422    508,160.1  cudaLaunchKernel     \n",
            "      0.0        4,163,960          3   1,387,986.7   1,942,386.0     103,788   2,117,786  1,115,601.2  cudaFree             \n",
            "\n",
            "[6/8] Executing 'gpukernsum' stats report\n",
            "\n",
            "CUDA Kernel Statistics:\n",
            "\n",
            " Time (%)  Total Time (ns)  Instances    Avg (ns)      Med (ns)     Min (ns)    Max (ns)   StdDev (ns)                   Name                 \n",
            " --------  ---------------  ---------  ------------  ------------  ----------  ----------  -----------  --------------------------------------\n",
            "    100.0    8,368,033,812        286  29,258,859.5  27,777,570.0  25,844,330  42,022,958  3,241,231.5  jacobi_step(float *, float *, float *)\n",
            "\n",
            "[7/8] Executing 'gpumemtimesum' stats report\n",
            "\n",
            "CUDA Memory Operation Statistics (by time):\n",
            "\n",
            " Time (%)  Total Time (ns)   Count   Avg (ns)  Med (ns)  Min (ns)  Max (ns)  StdDev (ns)              Operation            \n",
            " --------  ---------------  -------  --------  --------  --------  --------  -----------  ---------------------------------\n",
            "     78.1    3,003,008,818  946,104   3,174.1   2,591.0     2,335    89,983      2,820.8  [CUDA Unified Memory memcpy HtoD]\n",
            "     21.9      842,757,316   56,448  14,929.8   2,527.0     1,887    95,104     22,768.0  [CUDA Unified Memory memcpy DtoH]\n",
            "\n",
            "[8/8] Executing 'gpumemsizesum' stats report\n",
            "\n",
            "CUDA Memory Operation Statistics (by size):\n",
            "\n",
            " Total (MB)   Count   Avg (MB)  Med (MB)  Min (MB)  Max (MB)  StdDev (MB)              Operation            \n",
            " ----------  -------  --------  --------  --------  --------  -----------  ---------------------------------\n",
            "  9,682.551   56,448     0.172     0.008     0.004     1.044        0.299  [CUDA Unified Memory memcpy DtoH]\n",
            "  9,649.254  946,104     0.010     0.004     0.004     1.044        0.033  [CUDA Unified Memory memcpy HtoD]\n",
            "\n",
            "Generated:\n",
            "    /home/source_code/lab6/jacobi_step4.qdstrm\n",
            "    /home/source_code/lab6/jacobi_step4.nsys-rep\n",
            "    /home/source_code/lab6/jacobi_step4.sqlite\n"
          ]
        }
      ],
      "source": [
        "!cd /home/source_code/lab6 && make jacobi_step4 && nsys profile --stats=true -o jacobi_step4 -f true ./jacobi_step4"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Download the report by running the below cell and open the report via the Nsight Systems user interface (UI)."
      ],
      "metadata": {
        "id": "77g7PLlUy4k9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download('/home/source_code/lab6/jacobi_step4.nsys-rep')"
      ],
      "metadata": {
        "id": "Q_dIzBJZy43M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cp_39IcRvIOt"
      },
      "source": [
        "Let's check the NVTX ranges in the \"Events View\". We can see that the \"Jacobi Step\" is significantly faster but the \"Swap data\" is slower than before.\n",
        "\n",
        "<!--<img src=\"images/jacobi_4_.png\" width=\"40%\">-->\n",
        "<img src=\"https://drive.google.com/uc?export=download&id=1K74vlMuj1MZ016UQWmR4qbpTvSBT-NxX\">\n",
        "\n",
        "If we look at the CUDA row, and zoom in, we see all those gaps that are marked as \"Swap data\" regions on the NVTX row. There is a lot of data movement from host to device in `jacobi_step()` kernel and device to host in the `swap_data()` function (due to the Unified Memory usage).\n",
        "\n",
        "<!--<img src=\"images/jacobi_4_1.png\" width=\"80%\">-->\n",
        "<img src=\"https://drive.google.com/uc?export=download&id=1xyy36iJH9hHruhNkeFAH9QL4ATvM_WRX\">\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nRiRaKCsvIOt"
      },
      "source": [
        "### Step 5: Port the `swap_data` Kernel to GPU using CUDA\n",
        "\n",
        "We port the `swap_data()` function to the GPU using CUDA to do most of the computation on the device and reduce the data movement by keeping most of the data on the GPU.\n",
        "\n",
        "**Understand and analyze** the code:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cat /home/source_code/lab6/jacobi_step5.cpp"
      ],
      "metadata": {
        "id": "l6VktLRMdDzt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e3f63b70-c2f7-4e5d-c312-6a67c0de1c27"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "// Copyright (c) 2022 NVIDIA Corporation.  All rights reserved.\n",
            "\n",
            "#include <iostream>\n",
            "#include <iomanip>\n",
            "#include <cmath>\n",
            "#include <limits>\n",
            "#include <ctime>\n",
            "#include <nvToolsExt.h>\n",
            "\n",
            "#define N 2048\n",
            "\n",
            "#define IDX(i, j) ((j) + (i) * N)\n",
            "\n",
            "// error checking macro\n",
            "#define cudaCheckErrors(msg)                                    \\\n",
            "    do {                                                        \\\n",
            "        cudaError_t __err = cudaGetLastError();                 \\\n",
            "        if (__err != cudaSuccess) {                             \\\n",
            "            fprintf(stderr, \"Fatal error: %s (%s at %s:%d)\\n\",  \\\n",
            "                    msg, cudaGetErrorString(__err),             \\\n",
            "                    __FILE__, __LINE__);                        \\\n",
            "            fprintf(stderr, \"*** FAILED - ABORTING\\n\");         \\\n",
            "            exit(1);                                            \\\n",
            "        }                                                       \\\n",
            "    } while (0)\n",
            "\n",
            "void allocate_memory (float** f, float** f_old, float** error) {\n",
            "    cudaMallocManaged(f, N * N * sizeof(float));\n",
            "    cudaMallocManaged(f_old, N * N * sizeof(float));\n",
            "    cudaMallocManaged(error, sizeof(float));\n",
            "    cudaCheckErrors(\"Memory allocation\");\n",
            "}\n",
            "\n",
            "void free_memory (float* f, float* f_old, float* error) {\n",
            "    cudaFree(f);\n",
            "    cudaFree(f_old);\n",
            "    cudaFree(error);\n",
            "    cudaCheckErrors(\"Memory deallocation\");\n",
            "}\n",
            "\n",
            "void initialize_data (float* f) {\n",
            "    // Set up simple sinusoidal boundary conditions\n",
            "    for (int j = 0; j < N; ++j) {\n",
            "        for (int i = 0; i < N; ++i) {\n",
            "\n",
            "            if (i == 0 || i == N-1) {\n",
            "                f[IDX(i,j)] = sin(j * 2 * M_PI / (N - 1));\n",
            "            }\n",
            "            else if (j == 0 || j == N-1) {\n",
            "                f[IDX(i,j)] = sin(i * 2 * M_PI / (N - 1));\n",
            "            }\n",
            "            else {\n",
            "                f[IDX(i,j)] = 0.0f;\n",
            "            }\n",
            "\n",
            "        }\n",
            "    }\n",
            "}\n",
            "\n",
            "__global__ void jacobi_step (float* f, float* f_old, float* error) {\n",
            "    int i = threadIdx.x + blockIdx.x * blockDim.x;\n",
            "    int j = threadIdx.y + blockIdx.y * blockDim.y;\n",
            "\n",
            "    if (j >= 1 && j <= N-2) {\n",
            "        if (i >= 1 && i <= N-2) {\n",
            "            f[IDX(i,j)] = 0.25f * (f_old[IDX(i+1,j)] + f_old[IDX(i-1,j)] +\n",
            "                                   f_old[IDX(i,j+1)] + f_old[IDX(i,j-1)]);\n",
            "\n",
            "            float df = f[IDX(i,j)] - f_old[IDX(i,j)];\n",
            "            atomicAdd(error, df * df);\n",
            "        }\n",
            "    }\n",
            "}\n",
            "\n",
            "__global__ void swap_data (float* f, float* f_old) {\n",
            "    int i = threadIdx.x + blockIdx.x * blockDim.x;\n",
            "    int j = threadIdx.y + blockIdx.y * blockDim.y;\n",
            "\n",
            "    if (j >= 1 && j <= N-2) {\n",
            "        if (i >= 1 && i <= N-2) {\n",
            "            f_old[IDX(i,j)] = f[IDX(i,j)];\n",
            "        }\n",
            "    }\n",
            "}\n",
            "\n",
            "int main () {\n",
            "    // Begin wall timing\n",
            "    std::clock_t start_time = std::clock();\n",
            "\n",
            "    float* f;\n",
            "    float* f_old;\n",
            "    float* error;\n",
            "\n",
            "    // Reserve space for the scalar field and the \"old\" copy of the data\n",
            "    nvtxRangePush(\"Allocate memory\");\n",
            "    allocate_memory(&f, &f_old, &error);\n",
            "    nvtxRangePop();\n",
            "\n",
            "    // Initialize data (we'll do this on both f and f_old, so that we don't\n",
            "    // have to worry about the boundary points later)\n",
            "    nvtxRangePush(\"Initialize data\");\n",
            "    initialize_data(f);\n",
            "    initialize_data(f_old);\n",
            "    nvtxRangePop();\n",
            "\n",
            "    // Initialize error to a large number\n",
            "    *error = std::numeric_limits<float>::max();\n",
            "    const float tolerance = 1.e-4f;\n",
            "\n",
            "    // Iterate until we're converged (but set a cap on the maximum number of\n",
            "    // iterations to avoid any possible hangs)\n",
            "    const int max_iters = 1000;\n",
            "    int num_iters = 0;\n",
            "\n",
            "    while (*error > tolerance && num_iters < max_iters) {\n",
            "        // Initialize error to zero (we'll add to it the following step)\n",
            "        *error = 0.0f;\n",
            "\n",
            "        // Perform a Jacobi relaxation step\n",
            "        nvtxRangePush(\"Jacobi step\");\n",
            "        jacobi_step<<<dim3(N / 32, N / 32), dim3(32, 32)>>>(f, f_old, error);\n",
            "        cudaDeviceSynchronize();\n",
            "        nvtxRangePop();\n",
            "\n",
            "        // Swap the old data and the new data\n",
            "        // We're doing this explicitly for pedagogical purposes, even though\n",
            "        // in this specific application a std::swap would have been OK\n",
            "        nvtxRangePush(\"Swap data\");\n",
            "        swap_data<<<dim3(N / 32, N / 32), dim3(32, 32)>>>(f, f_old);\n",
            "        cudaDeviceSynchronize();\n",
            "        nvtxRangePop();\n",
            "\n",
            "        // Normalize the L2-norm of the error by the number of data points\n",
            "        // and then take the square root\n",
            "        *error = std::sqrt(*error / (N * N));\n",
            "\n",
            "        // Periodically print out the current error\n",
            "        if (num_iters % 25 == 0) {\n",
            "            std::cout << \"Error after iteration \" << num_iters << \" = \" << *error << std::endl;\n",
            "        }\n",
            "\n",
            "        // Increment the iteration count\n",
            "        ++num_iters;\n",
            "    }\n",
            "\n",
            "    // If we took fewer than max_iters steps and the error is below the tolerance,\n",
            "    // we succeeded. Otherwise, we failed.\n",
            "\n",
            "    if (*error <= tolerance && num_iters < max_iters) {\n",
            "        std::cout << \"Success!\" << std::endl;\n",
            "    }\n",
            "    else {\n",
            "        std::cout << \"Failure!\" << std::endl;\n",
            "        return -1;\n",
            "    }\n",
            "\n",
            "    // Clean up memory allocations\n",
            "    nvtxRangePush(\"Free memory\");\n",
            "    free_memory(f, f_old, error);\n",
            "    nvtxRangePop();\n",
            "\n",
            "    // End wall timing\n",
            "    double duration = (std::clock() - start_time) / (double) CLOCKS_PER_SEC;\n",
            "    std::cout << \"Run time = \" << std::setprecision(4) << duration << \" seconds\" << std::endl;\n",
            "\n",
            "    return 0;\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, compile and profile the code.\n"
      ],
      "metadata": {
        "id": "W7DYVuOrdEHY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "eiXO_mhBvIOt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "08190bde-4cf3-43a8-d3e5-b2c7dbe0a4bc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc -o jacobi_step5 -x cu -lnvToolsExt -lineinfo jacobi_step5.cpp\n",
            "Warning: LBR backtrace method is not supported on this platform. DWARF backtrace method will be used.\n",
            "Error after iteration 0 = 0.00781058\n",
            "Error after iteration 25 = 0.000608074\n",
            "Error after iteration 50 = 0.000366185\n",
            "Error after iteration 75 = 0.00027131\n",
            "Error after iteration 100 = 0.000219121\n",
            "Error after iteration 125 = 0.000185579\n",
            "Error after iteration 150 = 0.000161997\n",
            "Error after iteration 175 = 0.000144383\n",
            "Error after iteration 200 = 0.000130679\n",
            "Error after iteration 225 = 0.000119665\n",
            "Error after iteration 250 = 0.000110599\n",
            "Error after iteration 275 = 0.000102984\n",
            "Success!\n",
            "Run time = 3.323 seconds\n",
            "Generating '/tmp/nsys-report-ea9e.qdstrm'\n",
            "[1/8] [========================100%] jacobi_step5.nsys-rep\n",
            "Importer error status: Importation succeeded with non-fatal errors.\n",
            "**** Analysis failed with:\n",
            "Status: TargetProfilingFailed\n",
            "Props {\n",
            "  Items {\n",
            "    Type: DeviceId\n",
            "    Value: \"Local (CLI)\"\n",
            "  }\n",
            "}\n",
            "Error {\n",
            "  Type: RuntimeError\n",
            "  SubError {\n",
            "    Type: ProcessEventsError\n",
            "    Props {\n",
            "      Items {\n",
            "        Type: ErrorText\n",
            "        Value: \"/build/agent/work/20a3cfcd1c25021d/QuadD/Host/Analysis/Modules/TraceProcessEvent.cpp(45): Throw in function const string& {anonymous}::GetCudaCallbackName(bool, uint32_t, const QuadDAnalysis::MoreInjection&)\\nDynamic exception type: boost::exception_detail::clone_impl<QuadDCommon::InvalidArgumentException>\\nstd::exception::what: InvalidArgumentException\\n[QuadDCommon::tag_message*] = Unknown driver API function index: 673\\n\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n",
            "\n",
            "**** Errors occurred while processing the raw events. ****\n",
            "**** Please see the Diagnostics Summary page after opening the report file in GUI. ****\n",
            "[2/8] [========================100%] jacobi_step5.sqlite\n",
            "[3/8] Executing 'nvtxsum' stats report\n",
            "\n",
            "NVTX Range Statistics:\n",
            "\n",
            " Time (%)  Total Time (ns)  Instances    Avg (ns)       Med (ns)      Min (ns)     Max (ns)    StdDev (ns)   Style        Range     \n",
            " --------  ---------------  ---------  -------------  -------------  -----------  -----------  -----------  -------  ---------------\n",
            "     76.4    2,570,926,564        288    8,926,828.3    8,411,038.0    8,393,424   33,690,504  2,151,204.6  PushPop  Jacobi step    \n",
            "     14.2      477,293,870          1  477,293,870.0  477,293,870.0  477,293,870  477,293,870          0.0  PushPop  Allocate memory\n",
            "      5.3      177,639,539          1  177,639,539.0  177,639,539.0  177,639,539  177,639,539          0.0  PushPop  Initialize data\n",
            "      4.0      133,769,868        288      464,478.7      433,864.0      424,862    2,289,088    141,513.0  PushPop  Swap data      \n",
            "      0.1        3,786,457          1    3,786,457.0    3,786,457.0    3,786,457    3,786,457          0.0  PushPop  Free memory    \n",
            "\n",
            "[4/8] Executing 'osrtsum' stats report\n",
            "\n",
            "Operating System Runtime API Statistics:\n",
            "\n",
            " Time (%)  Total Time (ns)  Num Calls     Avg (ns)        Med (ns)     Min (ns)     Max (ns)       StdDev (ns)         Name     \n",
            " --------  ---------------  ---------  ---------------  -------------  ---------  -------------  ---------------  --------------\n",
            "     56.8    5,543,758,143        282     19,658,716.8   10,073,278.5      3,318    100,146,818     27,977,495.3  poll          \n",
            "     36.8    3,589,201,624          3  1,196,400,541.3  178,704,641.0  3,439,386  3,407,057,597  1,916,489,744.5  sem_wait      \n",
            "      5.6      549,248,223        249      2,205,816.2    2,064,716.0     11,072     20,820,374      1,732,470.1  sem_timedwait \n",
            "      0.8       75,252,285        523        143,885.8       13,352.0      1,054     21,570,013      1,173,891.3  ioctl         \n",
            "      0.0        3,757,266         25        150,290.6        6,635.0      1,171      1,820,546        480,617.2  mmap          \n",
            "      0.0        1,970,355         31         63,559.8        9,993.0      5,528      1,453,945        258,546.3  mmap64        \n",
            "      0.0          452,518         49          9,235.1        8,492.0      2,276         17,229          3,030.6  open64        \n",
            "      0.0          314,145         56          5,609.7        4,185.0      1,603         20,628          4,263.3  fopen         \n",
            "      0.0          236,596         14         16,899.7       10,471.0      8,344         96,660         23,039.7  putc          \n",
            "      0.0          184,284          4         46,071.0       42,373.5     39,565         59,972          9,470.3  pthread_create\n",
            "      0.0           78,530         42          1,869.8        1,557.5      1,022          6,321          1,015.5  fclose        \n",
            "      0.0           76,924          6         12,820.7        8,802.0      4,270         36,063         12,098.3  fgets         \n",
            "      0.0           56,055          9          6,228.3        5,668.0      2,025         18,446          4,989.9  munmap        \n",
            "      0.0           48,658         11          4,423.5        5,802.0      1,472          7,222          2,283.3  write         \n",
            "      0.0           45,039         15          3,002.6        1,343.0      1,214         16,039          4,235.4  fwrite        \n",
            "      0.0           34,448         12          2,870.7        1,729.5      1,010          9,201          2,384.9  read          \n",
            "      0.0           29,934          5          5,986.8        4,620.0      3,095          9,815          2,857.9  open          \n",
            "      0.0           27,984          2         13,992.0       13,992.0      9,267         18,717          6,682.2  socket        \n",
            "      0.0           16,683          6          2,780.5        2,340.0      1,387          5,023          1,298.3  fread         \n",
            "      0.0           12,442          5          2,488.4        1,553.0      1,003          5,123          1,759.3  fcntl         \n",
            "      0.0           10,886          1         10,886.0       10,886.0     10,886         10,886              0.0  connect       \n",
            "      0.0            7,950          1          7,950.0        7,950.0      7,950          7,950              0.0  pipe2         \n",
            "      0.0            7,537          1          7,537.0        7,537.0      7,537          7,537              0.0  fopen64       \n",
            "      0.0            6,012          2          3,006.0        3,006.0      2,049          3,963          1,353.4  fflush        \n",
            "      0.0            2,070          1          2,070.0        2,070.0      2,070          2,070              0.0  bind          \n",
            "      0.0            1,607          1          1,607.0        1,607.0      1,607          1,607              0.0  listen        \n",
            "\n",
            "[5/8] Executing 'cudaapisum' stats report\n",
            "\n",
            "CUDA API Statistics:\n",
            "\n",
            " Time (%)  Total Time (ns)  Num Calls   Avg (ns)     Med (ns)    Min (ns)  Max (ns)   StdDev (ns)          Name         \n",
            " --------  ---------------  ---------  -----------  -----------  --------  ---------  -----------  ---------------------\n",
            "     89.7        3,778,956          3  1,259,652.0  1,748,387.0   128,358  1,902,211    982,743.6  cudaFree             \n",
            "      9.8          412,542          1    412,542.0    412,542.0   412,542    412,542          0.0  cudaDeviceSynchronize\n",
            "      0.5           21,792          1     21,792.0     21,792.0    21,792     21,792          0.0  cudaLaunchKernel     \n",
            "\n",
            "[6/8] Executing 'gpukernsum' stats report\n",
            "SKIPPED: /home/source_code/lab6/jacobi_step5.sqlite does not contain CUDA kernel data.\n",
            "[7/8] Executing 'gpumemtimesum' stats report\n",
            "\n",
            "CUDA Memory Operation Statistics (by time):\n",
            "\n",
            " Time (%)  Total Time (ns)  Count  Avg (ns)  Med (ns)  Min (ns)  Max (ns)  StdDev (ns)              Operation            \n",
            " --------  ---------------  -----  --------  --------  --------  --------  -----------  ---------------------------------\n",
            "     95.9       10,956,935  3,454   3,172.2   2,591.0     2,463    67,200      2,893.7  [CUDA Unified Memory memcpy HtoD]\n",
            "      4.1          468,889    293   1,600.3   1,472.0     1,440     6,912        707.6  [CUDA Unified Memory memcpy DtoH]\n",
            "\n",
            "[8/8] Executing 'gpumemsizesum' stats report\n",
            "\n",
            "CUDA Memory Operation Statistics (by size):\n",
            "\n",
            " Total (MB)  Count  Avg (MB)  Med (MB)  Min (MB)  Max (MB)  StdDev (MB)              Operation            \n",
            " ----------  -----  --------  --------  --------  --------  -----------  ---------------------------------\n",
            "     35.103  3,454     0.010     0.004     0.004     0.786        0.034  [CUDA Unified Memory memcpy HtoD]\n",
            "      1.487    293     0.005     0.004     0.004     0.061        0.007  [CUDA Unified Memory memcpy DtoH]\n",
            "\n",
            "Generated:\n",
            "    /home/source_code/lab6/jacobi_step5.qdstrm\n",
            "    /home/source_code/lab6/jacobi_step5.nsys-rep\n",
            "    /home/source_code/lab6/jacobi_step5.sqlite\n"
          ]
        }
      ],
      "source": [
        "!cd /home/source_code/lab6 && make jacobi_step5 && nsys profile --stats=true -o jacobi_step5 -f true ./jacobi_step5"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Download the report by running the below cell and open the report via the Nsight Systems user interface (UI)."
      ],
      "metadata": {
        "id": "NvWEoaftzOls"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download('/home/source_code/lab6/jacobi_step5.nsys-rep')"
      ],
      "metadata": {
        "id": "-HHqMHouzDTW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DKksjijXvIOt"
      },
      "source": [
        "Let's check the NVTX ranges in the \"Events View\". We can see that the application is much faster now (\"Swap data\" is now faster than before).\n",
        "\n",
        "<!--<img src=\"images/jacobi_5_0.png\" width=\"40%\">-->\n",
        "<img src=\"https://drive.google.com/uc?export=download&id=1GvO6tXO8ERMjUAEMKumZk6cm5O9hgP0i\">\n",
        "\n",
        "The timeline of the application is shown below.\n",
        "\n",
        "<!--<img src=\"images/jacobi_5_1.png\" width=\"80%\">-->\n",
        "<img src=\"https://drive.google.com/uc?export=download&id=1Z0DbsVO-etdHsyy98nX_3SNbrim_oWFg\">\n",
        "\n",
        "\n",
        "By looking at the CUDA row, it is clear that most of the application runtime is now spent in kernels and the data movement (green rectangles) is also reduced. Let's dig deeper and analyze the kernels in Nsight Compute to see if there are any other optimizations we can apply."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IcDyi7BRvIOu"
      },
      "source": [
        "\n",
        "### Step 6: Analyze and Improve the Kernels\n",
        "\n",
        "In this section, we want to find out if the kernel is compute-bound, memory-bound, or latency-bound. To ensure the kernel is not limited by latency, we need to expose enough work to keep a large number of threads running on the GPU. In this example, `N` is equal to 2048, which means the problem size is `2048 x 2048`. Since the order of magnitude number of threads a modern GPU can run simultaneously is O(100k), then we probably have enough work to keep the device busy.\n",
        "\n",
        "In the case of memory bound or compute bound, we need to think of arithmetic intensity which is the ratio between compute work (FLOPs) and data movement (bytes) expressed as Floating Point Operations per second (FLOP/S). If this ratio is an order 10, then it would be compute bound.\n",
        "\n",
        "```cpp\n",
        "f[IDX(i,j)] = 0.25f * (f_old[IDX(i+1,j)] + f_old[IDX(i-1,j)] +\n",
        "                      f_old[IDX(i,j+1)] + f_old[IDX(i,j-1)]);\n",
        "```\n",
        "\n",
        "The `jacobi_step()` kernel computes four floating point operations (three adds and one multiply) and moves four words (each 4 bytes for single precision floating point), so the arithmetic intensity is `4 (FLOPs) / 16 (bytes) = 0.25 FLOPs / byte` and it seems to be in the memory bandwidth region.\n",
        "\n",
        "Now, profile the kernel with Nsight Compute to verify our hypotheses.\n",
        "\n",
        "We only profile one invocation of the kernel since it has similar performance characteristics, and to allow the device to warmp up we skip the first few."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "CF0OHt-rvIOu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8d41d0ee-7ba3-40d1-9c87-7a92139edd0d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==PROF== Connected to process 12354 (/home/source_code/lab6/jacobi_step5)\n",
            "Error after iteration 0 = 0.00781058\n",
            "==PROF== Profiling \"jacobi_step\": 0%....50%....100% - 31 passes\n",
            "Error after iteration 25 = 0.000608073\n",
            "Error after iteration 50 = 0.000366185\n",
            "Error after iteration 75 = 0.00027131\n",
            "Error after iteration 100 = 0.000219121\n",
            "Error after iteration 125 = 0.00018558\n",
            "Error after iteration 150 = 0.000161997\n",
            "Error after iteration 175 = 0.000144383\n",
            "Error after iteration 200 = 0.000130677\n",
            "Error after iteration 225 = 0.000119665\n",
            "Error after iteration 250 = 0.000110599\n",
            "Error after iteration 275 = 0.000102984\n",
            "Success!\n",
            "Run time = 4.443 seconds\n",
            "==PROF== Disconnected from process 12354\n",
            "==PROF== Report: /home/source_code/lab6/jacobi_step5_0.ncu-rep\n"
          ]
        }
      ],
      "source": [
        "!cd /home/source_code/lab6 && ncu --launch-count 1 --launch-skip 5 -k --regex:jacobi -f -o jacobi_step5_0 --set full ./jacobi_step5"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Download the report by running the below cell and open the report via the Nsight Compute user interface (UI)."
      ],
      "metadata": {
        "id": "q8NeJ7zTzC-Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download('/home/source_code/lab6/jacobi_step5_0.ncu-rep')"
      ],
      "metadata": {
        "id": "aYyr9-cfziQ1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "09b550fe-ef3d-442a-8f28-f4b0d02fdb49"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_f04763b5-a487-4812-8387-41c615dc2f1f\", \"jacobi_step5_0.ncu-rep\", 149436)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0LBUGZvCvIOu"
      },
      "source": [
        "The \"Speed of Light Throughput\" section gives a high-level overview of the throughput for the compute and memory resources of the GPU for each unit. Based on this information, we can find the performance limiters and catagorize them into four possible combinations:\n",
        "\n",
        "- Compute Bound: SM>50% & Mem<50%\n",
        "- Bandwidth Bound: SM<50% & Mem>50%\n",
        "- Latency Bound: SM<50% & Mem<50%\n",
        "- Compute and Bandwidth Bound : SM>50% & Mem>50%\n",
        "\n",
        "According to the *GPU Speed of Light Throughput* section (see screenshot below), the kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance of the device it was run on. Since achieved compute throughput and/or memory bandwidth is below 60.0% of peak, the kernel is latency bound. The tool suggests looking at the *Scheduler Statistics* and *Warp State Statistics* for possible reasons.\n",
        "\n",
        "<!--<img src=\"images/jacobi_5_sol.png\" width=\"80%\">-->\n",
        "<img src=\"https://drive.google.com/uc?export=download&id=1vo9J4LlT9qgOpZaiJ-joyi48gvZwS9Fa\">\n",
        "\n",
        "\n",
        "The *Scheduler Statistics* shows the activity summary of the schedulers issuing instructions. Every scheduler can issue one instruction per cycle, but for this kernel, each scheduler only issues an instruction every ~1287 cycles. This causes underutilization of the hardware resources and leads to less than optimal performance.\n",
        "\n",
        "\n",
        "<!--<img src=\"/home/images/jacobi_5_schedule.png\" width=\"80%\">-->\n",
        "<img src=\"https://drive.google.com/uc?export=download&id=1f-FIk-7rret5LDdjDIZRCPTKjop6Tr1j\">\n",
        "\n",
        "\n",
        "Check the *Warp State Statistics* section  which presents an analysis  of the states of all warps  that spent cycles during the kernel execution. The warp states describe a warp's readiness or inability to issue its next instruction. As seen in the screenshot below, the most important stall reason is *LG (local/global) Throttle* which indicates extremely frequent memory instructions, according to the guided analysis rule (hover your mouse over each to see the description).\n",
        "\n",
        "<!--<img src=\"images/jacobi_5_warp.png\" width=\"80%\">-->\n",
        "<img src=\"https://drive.google.com/uc?export=download&id=1qDGuDwFHva1px_74l_kvepnA4QqV3-4S\">\n",
        "\n",
        "\n",
        "When we check the *Source Counters* section for the top stall locations in your source based on sampling data, we can see the kernel has uncoalesced global accesses (note: you can click on the links and go to the line where these occur).\n",
        "\n",
        "<!--<img src=\"images/jacobi_5_source.png\" width=\"80%\">-->\n",
        "<img src=\"https://drive.google.com/uc?export=download&id=1KHiijrNKvUVD0DPGDj7qNpujE-LPOUT0\">\n",
        "\n",
        "\n",
        "Last, looking at the *Occupancy* section, we achieved 71% occupancy which is the ratio of the number of active warps per multiprocessor to the maximum number of possible active warps. In other words, we are giving enough work to the device to keep it busy. So, the low memory throughput is a result of poor memory access patterns.\n",
        "\n",
        "<!--<img src=\"images/jacobi_5_occ.png\" width=\"80%\">-->\n",
        "<img src=\"https://drive.google.com/uc?export=download&id=1Ca50hodiUnNGJaW3rRqe1iNc7VPDx7aj\">\n",
        "\n",
        "To conclude, the reason for low memory throughput is poor memory access patterns which means the memory layout of our arrays does not map well with the threads (read more at [Analysis-Driven Optimization: Analyzing and Improving Performance with NVIDIA Nsight Compute](https://developer.nvidia.com/blog/analysis-driven-optimization-analyzing-and-improving-performance-with-nvidia-nsight-compute-part-2/)). Now,  profile the `swap_data()` kernel with Nsight Compute."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "ra7M_DOtvIOu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6202ab66-65f7-482e-ceef-c5dd9d2ea9c2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==PROF== Connected to process 13464 (/home/source_code/lab6/jacobi_step5)\n",
            "Error after iteration 0 = 0.00781058\n",
            "==PROF== Profiling \"swap_data\": 0%....50%....100% - 31 passes\n",
            "Error after iteration 25 = 0.000608074\n",
            "Error after iteration 50 = 0.000366184\n",
            "Error after iteration 75 = 0.000271309\n",
            "Error after iteration 100 = 0.000219121\n",
            "Error after iteration 125 = 0.000185579\n",
            "Error after iteration 150 = 0.000161997\n",
            "Error after iteration 175 = 0.000144383\n",
            "Error after iteration 200 = 0.000130677\n",
            "Error after iteration 225 = 0.000119665\n",
            "Error after iteration 250 = 0.000110599\n",
            "Error after iteration 275 = 0.000102984\n",
            "Success!\n",
            "Run time = 3.777 seconds\n",
            "==PROF== Disconnected from process 13464\n",
            "==PROF== Report: /home/source_code/lab6/jacobi_step5_1.ncu-rep\n"
          ]
        }
      ],
      "source": [
        "!cd /home/source_code/lab6 && ncu --launch-count 1 --launch-skip 5 -k --regex:swap_data -f -o jacobi_step5_1 --set full ./jacobi_step5"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Download the report by running the below cell and open the report via the Nsight Compute user interface (UI)."
      ],
      "metadata": {
        "id": "sTk2zxvgz0gD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download('/home/source_code/lab6/jacobi_step5_1.ncu-rep')"
      ],
      "metadata": {
        "id": "mHP_esFFz09a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "b61aeb41-b0c1-49a8-8a23-76a802abe615"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_7f00553f-a7bd-4954-9e74-ccee8f1d79bb\", \"jacobi_step5_1.ncu-rep\", 140576)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4cSbawuqvIOv"
      },
      "source": [
        "According to the *GPU Speed of Light Throughput* section (see screenshot below), the memory is more heavily utilized than compute and we need to look at the *Memory Workload Analysis* to identify the L2 bottleneck.\n",
        "\n",
        "<!--<img src=\"images/jacobi_swap_sol.png\" width=\"80%\">-->\n",
        "<img src=\"https://drive.google.com/uc?export=download&id=1kf2IowIQ1K8q4VANTMHjY5i3wrFv9jlz\">\n",
        "\n",
        "\n",
        "The *Memory Workload Analysis* section tells us that the kernel has a poor memory access pattern. Rather than accessing 4 bytes per thread per memory request, there are `32x32 = 1023` bytes of cache data transfers per request which is 8 times more sector loads.\n",
        "\n",
        "<!--<img src=\"images/jacobi_swap_mem.png\" width=\"80%\">-->\n",
        "<img src=\"https://drive.google.com/uc?export=download&id=1rdEQQtRCfiBgdHw_RlIzBkXDL9b5Cc-9\">\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z5bJENdkvIOv"
      },
      "source": [
        "Compare the indexing scheme we used to the threading scheme. In a 2D threadblock, the `x` dimension is the contiguous dimension and the `y` dimension is the strided dimension. So, in a 32x32 thread block, each warp comprises of 32 threads in the `x` dimension and the `threadIdx.y` counts/enumerates 32 warps. To fix the uncoalessed memory access, we change `#define IDX(i, j) ((j) + (i) * N)` to `#define IDX(i, j) ((i) + (j) * N)`.\n",
        "\n",
        "**Understand and analyze** the code:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cat /home/source_code/lab6/jacobi_step6.cpp"
      ],
      "metadata": {
        "id": "WPa0vHJIlYMi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8c6c60af-8bb4-4b8b-b57a-390643d871c9"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "// Copyright (c) 2022 NVIDIA Corporation.  All rights reserved.\n",
            "\n",
            "#include <iostream>\n",
            "#include <iomanip>\n",
            "#include <cmath>\n",
            "#include <limits>\n",
            "#include <ctime>\n",
            "#include <nvToolsExt.h>\n",
            "\n",
            "#define N 2048\n",
            "\n",
            "#define IDX(i, j) ((i) + (j) * N)\n",
            "\n",
            "// error checking macro\n",
            "#define cudaCheckErrors(msg)                                    \\\n",
            "    do {                                                        \\\n",
            "        cudaError_t __err = cudaGetLastError();                 \\\n",
            "        if (__err != cudaSuccess) {                             \\\n",
            "            fprintf(stderr, \"Fatal error: %s (%s at %s:%d)\\n\",  \\\n",
            "                    msg, cudaGetErrorString(__err),             \\\n",
            "                    __FILE__, __LINE__);                        \\\n",
            "            fprintf(stderr, \"*** FAILED - ABORTING\\n\");         \\\n",
            "            exit(1);                                            \\\n",
            "        }                                                       \\\n",
            "    } while (0)\n",
            "\n",
            "void allocate_memory (float** f, float** f_old, float** error) {\n",
            "    cudaMallocManaged(f, N * N * sizeof(float));\n",
            "    cudaMallocManaged(f_old, N * N * sizeof(float));\n",
            "    cudaMallocManaged(error, sizeof(float));\n",
            "    cudaCheckErrors(\"Memory allocation\");\n",
            "}\n",
            "\n",
            "void free_memory (float* f, float* f_old, float* error) {\n",
            "    cudaFree(f);\n",
            "    cudaFree(f_old);\n",
            "    cudaFree(error);\n",
            "    cudaCheckErrors(\"Memory deallocation\");\n",
            "}\n",
            "\n",
            "void initialize_data (float* f) {\n",
            "    // Set up simple sinusoidal boundary conditions\n",
            "    for (int j = 0; j < N; ++j) {\n",
            "        for (int i = 0; i < N; ++i) {\n",
            "\n",
            "            if (i == 0 || i == N-1) {\n",
            "                f[IDX(i,j)] = sin(j * 2 * M_PI / (N - 1));\n",
            "            }\n",
            "            else if (j == 0 || j == N-1) {\n",
            "                f[IDX(i,j)] = sin(i * 2 * M_PI / (N - 1));\n",
            "            }\n",
            "            else {\n",
            "                f[IDX(i,j)] = 0.0f;\n",
            "            }\n",
            "\n",
            "        }\n",
            "    }\n",
            "}\n",
            "\n",
            "__global__ void jacobi_step (float* f, float* f_old, float* error) {\n",
            "    int i = threadIdx.x + blockIdx.x * blockDim.x;\n",
            "    int j = threadIdx.y + blockIdx.y * blockDim.y;\n",
            "\n",
            "    if (j >= 1 && j <= N-2) {\n",
            "        if (i >= 1 && i <= N-2) {\n",
            "            f[IDX(i,j)] = 0.25f * (f_old[IDX(i+1,j)] + f_old[IDX(i-1,j)] +\n",
            "                                   f_old[IDX(i,j+1)] + f_old[IDX(i,j-1)]);\n",
            "\n",
            "            float df = f[IDX(i,j)] - f_old[IDX(i,j)];\n",
            "            atomicAdd(error, df * df);\n",
            "        }\n",
            "    }\n",
            "}\n",
            "\n",
            "__global__ void swap_data (float* f, float* f_old) {\n",
            "    int i = threadIdx.x + blockIdx.x * blockDim.x;\n",
            "    int j = threadIdx.y + blockIdx.y * blockDim.y;\n",
            "\n",
            "    if (j >= 1 && j <= N-2) {\n",
            "        if (i >= 1 && i <= N-2) {\n",
            "            f_old[IDX(i,j)] = f[IDX(i,j)];\n",
            "        }\n",
            "    }\n",
            "}\n",
            "\n",
            "int main () {\n",
            "    // Begin wall timing\n",
            "    std::clock_t start_time = std::clock();\n",
            "\n",
            "    float* f;\n",
            "    float* f_old;\n",
            "    float* error;\n",
            "\n",
            "    // Reserve space for the scalar field and the \"old\" copy of the data\n",
            "    nvtxRangePush(\"Allocate memory\");\n",
            "    allocate_memory(&f, &f_old, &error);\n",
            "    nvtxRangePop();\n",
            "\n",
            "    // Initialize data (we'll do this on both f and f_old, so that we don't\n",
            "    // have to worry about the boundary points later)\n",
            "    nvtxRangePush(\"Initialize data\");\n",
            "    initialize_data(f);\n",
            "    initialize_data(f_old);\n",
            "    nvtxRangePop();\n",
            "\n",
            "    // Initialize error to a large number\n",
            "    *error = std::numeric_limits<float>::max();\n",
            "    const float tolerance = 1.e-4f;\n",
            "\n",
            "    // Iterate until we're converged (but set a cap on the maximum number of\n",
            "    // iterations to avoid any possible hangs)\n",
            "    const int max_iters = 1000;\n",
            "    int num_iters = 0;\n",
            "\n",
            "    while (*error > tolerance && num_iters < max_iters) {\n",
            "        // Initialize error to zero (we'll add to it the following step)\n",
            "        *error = 0.0f;\n",
            "\n",
            "        // Perform a Jacobi relaxation step\n",
            "        nvtxRangePush(\"Jacobi step\");\n",
            "        jacobi_step<<<dim3(N / 32, N / 32), dim3(32, 32)>>>(f, f_old, error);\n",
            "        cudaDeviceSynchronize();\n",
            "        nvtxRangePop();\n",
            "\n",
            "        // Swap the old data and the new data\n",
            "        // We're doing this explicitly for pedagogical purposes, even though\n",
            "        // in this specific application a std::swap would have been OK\n",
            "        nvtxRangePush(\"Swap data\");\n",
            "        swap_data<<<dim3(N / 32, N / 32), dim3(32, 32)>>>(f, f_old);\n",
            "        cudaDeviceSynchronize();\n",
            "        nvtxRangePop();\n",
            "\n",
            "        // Normalize the L2-norm of the error by the number of data points\n",
            "        // and then take the square root\n",
            "        *error = std::sqrt(*error / (N * N));\n",
            "\n",
            "        // Periodically print out the current error\n",
            "        if (num_iters % 25 == 0) {\n",
            "            std::cout << \"Error after iteration \" << num_iters << \" = \" << *error << std::endl;\n",
            "        }\n",
            "\n",
            "        // Increment the iteration count\n",
            "        ++num_iters;\n",
            "    }\n",
            "\n",
            "    // If we took fewer than max_iters steps and the error is below the tolerance,\n",
            "    // we succeeded. Otherwise, we failed.\n",
            "\n",
            "    if (*error <= tolerance && num_iters < max_iters) {\n",
            "        std::cout << \"Success!\" << std::endl;\n",
            "    }\n",
            "    else {\n",
            "        std::cout << \"Failure!\" << std::endl;\n",
            "        return -1;\n",
            "    }\n",
            "\n",
            "    // Clean up memory allocations\n",
            "    nvtxRangePush(\"Free memory\");\n",
            "    free_memory(f, f_old, error);\n",
            "    nvtxRangePop();\n",
            "\n",
            "    // End wall timing\n",
            "    double duration = (std::clock() - start_time) / (double) CLOCKS_PER_SEC;\n",
            "    std::cout << \"Run time = \" << std::setprecision(4) << duration << \" seconds\" << std::endl;\n",
            "\n",
            "    return 0;\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, compile and profile the code."
      ],
      "metadata": {
        "id": "Br1Ajr5YlgNp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "Wawn6fcnvIOv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2cd481cb-c90a-4ddb-d018-9350e884e214"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc -o jacobi_step6 -x cu -lnvToolsExt -lineinfo jacobi_step6.cpp\n",
            "Warning: LBR backtrace method is not supported on this platform. DWARF backtrace method will be used.\n",
            "Error after iteration 0 = 0.00781058\n",
            "Error after iteration 25 = 0.000608074\n",
            "Error after iteration 50 = 0.000366183\n",
            "Error after iteration 75 = 0.000271311\n",
            "Error after iteration 100 = 0.000219121\n",
            "Error after iteration 125 = 0.00018558\n",
            "Error after iteration 150 = 0.000161997\n",
            "Error after iteration 175 = 0.000144383\n",
            "Error after iteration 200 = 0.000130678\n",
            "Error after iteration 225 = 0.000119665\n",
            "Error after iteration 250 = 0.000110599\n",
            "Error after iteration 275 = 0.000102984\n",
            "Success!\n",
            "Run time = 3.164 seconds\n",
            "Generating '/tmp/nsys-report-4494.qdstrm'\n",
            "[1/8] [========================100%] jacobi_step6.nsys-rep\n",
            "Importer error status: Importation succeeded with non-fatal errors.\n",
            "**** Analysis failed with:\n",
            "Status: TargetProfilingFailed\n",
            "Props {\n",
            "  Items {\n",
            "    Type: DeviceId\n",
            "    Value: \"Local (CLI)\"\n",
            "  }\n",
            "}\n",
            "Error {\n",
            "  Type: RuntimeError\n",
            "  SubError {\n",
            "    Type: ProcessEventsError\n",
            "    Props {\n",
            "      Items {\n",
            "        Type: ErrorText\n",
            "        Value: \"/build/agent/work/20a3cfcd1c25021d/QuadD/Host/Analysis/Modules/TraceProcessEvent.cpp(45): Throw in function const string& {anonymous}::GetCudaCallbackName(bool, uint32_t, const QuadDAnalysis::MoreInjection&)\\nDynamic exception type: boost::exception_detail::clone_impl<QuadDCommon::InvalidArgumentException>\\nstd::exception::what: InvalidArgumentException\\n[QuadDCommon::tag_message*] = Unknown driver API function index: 673\\n\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n",
            "\n",
            "**** Errors occurred while processing the raw events. ****\n",
            "**** Please see the Diagnostics Summary page after opening the report file in GUI. ****\n",
            "[2/8] [========================100%] jacobi_step6.sqlite\n",
            "[3/8] Executing 'nvtxsum' stats report\n",
            "\n",
            "NVTX Range Statistics:\n",
            "\n",
            " Time (%)  Total Time (ns)  Instances    Avg (ns)       Med (ns)      Min (ns)     Max (ns)    StdDev (ns)   Style        Range     \n",
            " --------  ---------------  ---------  -------------  -------------  -----------  -----------  -----------  -------  ---------------\n",
            "     80.9    2,566,566,475        288    8,911,689.1    8,476,881.5    8,444,258   24,374,611  1,673,168.7  PushPop  Jacobi step    \n",
            "     16.0      508,011,095          1  508,011,095.0  508,011,095.0  508,011,095  508,011,095          0.0  PushPop  Allocate memory\n",
            "      1.6       50,142,793        288      174,106.9      169,061.0      162,622      268,778     18,493.5  PushPop  Swap data      \n",
            "      1.4       43,057,294          1   43,057,294.0   43,057,294.0   43,057,294   43,057,294          0.0  PushPop  Initialize data\n",
            "      0.1        3,726,234          1    3,726,234.0    3,726,234.0    3,726,234    3,726,234          0.0  PushPop  Free memory    \n",
            "\n",
            "[4/8] Executing 'osrtsum' stats report\n",
            "\n",
            "Operating System Runtime API Statistics:\n",
            "\n",
            " Time (%)  Total Time (ns)  Num Calls     Avg (ns)        Med (ns)     Min (ns)     Max (ns)       StdDev (ns)         Name     \n",
            " --------  ---------------  ---------  ---------------  -------------  ---------  -------------  ---------------  --------------\n",
            "     56.4    5,160,774,088        262     19,697,611.0   10,077,676.5      3,869    100,145,597     28,046,231.3  poll          \n",
            "     37.2    3,400,536,539          3  1,133,512,179.7  184,795,516.0  6,729,905  3,209,011,118  1,799,638,497.8  sem_wait      \n",
            "      5.5      501,541,536        232      2,161,817.0    2,072,324.0     14,409     20,817,202      1,460,403.2  sem_timedwait \n",
            "      0.8       74,857,024        523        143,130.1       15,117.0      1,163     18,839,022      1,095,245.5  ioctl         \n",
            "      0.0        3,756,438         26        144,478.4        8,024.5      1,076      1,785,112        471,128.4  mmap          \n",
            "      0.0        1,681,112         31         54,229.4        8,744.0      5,439      1,106,596        196,222.7  mmap64        \n",
            "      0.0          547,260         49         11,168.6        9,735.0      3,240         36,543          5,604.0  open64        \n",
            "      0.0          335,464         56          5,990.4        4,398.5      1,885         23,720          4,671.0  fopen         \n",
            "      0.0          270,731         14         19,337.9       10,179.0      8,253         62,509         19,403.7  putc          \n",
            "      0.0          214,134          4         53,533.5       53,954.0     39,962         66,264         11,063.3  pthread_create\n",
            "      0.0           86,694          6         14,449.0       10,574.5      5,314         36,811         12,000.2  fgets         \n",
            "      0.0           84,976         43          1,976.2        1,547.0      1,041          7,073          1,104.5  fclose        \n",
            "      0.0           54,882         11          4,989.3        6,274.0      1,368          7,818          2,376.0  write         \n",
            "      0.0           51,304         16          3,206.5        1,729.5      1,218         17,533          4,298.3  fwrite        \n",
            "      0.0           40,767          9          4,529.7        3,385.0      1,800         10,035          2,689.1  munmap        \n",
            "      0.0           32,629          5          6,525.8        5,132.0      4,287         10,134          2,570.6  open          \n",
            "      0.0           32,064         12          2,672.0        1,817.5      1,024         11,404          2,805.4  read          \n",
            "      0.0           28,700          2         14,350.0       14,350.0      9,449         19,251          6,931.1  socket        \n",
            "      0.0           20,197          6          3,366.2        2,581.0      2,215          5,948          1,547.9  fread         \n",
            "      0.0           14,747          5          2,949.4        1,627.0      1,000          6,161          2,265.6  fcntl         \n",
            "      0.0           12,613          1         12,613.0       12,613.0     12,613         12,613              0.0  connect       \n",
            "      0.0            8,488          1          8,488.0        8,488.0      8,488          8,488              0.0  pipe2         \n",
            "      0.0            8,177          1          8,177.0        8,177.0      8,177          8,177              0.0  fopen64       \n",
            "      0.0            7,934          3          2,644.7        2,060.0      1,972          3,902          1,089.8  fflush        \n",
            "      0.0            2,041          1          2,041.0        2,041.0      2,041          2,041              0.0  bind          \n",
            "      0.0            1,229          1          1,229.0        1,229.0      1,229          1,229              0.0  listen        \n",
            "\n",
            "[5/8] Executing 'cudaapisum' stats report\n",
            "SKIPPED: /home/source_code/lab6/jacobi_step6.sqlite does not contain CUDA trace data.\n",
            "[6/8] Executing 'gpukernsum' stats report\n",
            "SKIPPED: /home/source_code/lab6/jacobi_step6.sqlite does not contain CUDA kernel data.\n",
            "[7/8] Executing 'gpumemtimesum' stats report\n",
            "\n",
            "CUDA Memory Operation Statistics (by time):\n",
            "\n",
            " Time (%)  Total Time (ns)  Count  Avg (ns)  Med (ns)  Min (ns)  Max (ns)  StdDev (ns)              Operation            \n",
            " --------  ---------------  -----  --------  --------  --------  --------  -----------  ---------------------------------\n",
            "     91.5        5,147,954  1,029   5,002.9   2,559.0     2,112    88,640     11,747.3  [CUDA Unified Memory memcpy HtoD]\n",
            "      8.5          475,257    293   1,622.0   1,504.0     1,440     6,880        655.1  [CUDA Unified Memory memcpy DtoH]\n",
            "\n",
            "[8/8] Executing 'gpumemsizesum' stats report\n",
            "\n",
            "CUDA Memory Operation Statistics (by size):\n",
            "\n",
            " Total (MB)  Count  Avg (MB)  Med (MB)  Min (MB)  Max (MB)  StdDev (MB)              Operation            \n",
            " ----------  -----  --------  --------  --------  --------  -----------  ---------------------------------\n",
            "     34.230  1,029     0.033     0.004     0.004     1.044        0.142  [CUDA Unified Memory memcpy HtoD]\n",
            "      1.487    293     0.005     0.004     0.004     0.061        0.007  [CUDA Unified Memory memcpy DtoH]\n",
            "\n",
            "Generated:\n",
            "    /home/source_code/lab6/jacobi_step6.qdstrm\n",
            "    /home/source_code/lab6/jacobi_step6.nsys-rep\n",
            "    /home/source_code/lab6/jacobi_step6.sqlite\n"
          ]
        }
      ],
      "source": [
        "!cd /home/source_code/lab6 && make jacobi_step6 && nsys profile --stats=true -o jacobi_step6 -f true ./jacobi_step6"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Download the report by running the below cell and open the report via the Nsight Systems user interface (UI)."
      ],
      "metadata": {
        "id": "erprZ10D0DJH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download('/home/source_code/lab6/jacobi_step6.nsys-rep')"
      ],
      "metadata": {
        "id": "6G-9dDWQ0DXN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RTPMZx9NvIOv"
      },
      "source": [
        "We can clearly see we made some overall improvements and reduced the total execution time.\n",
        "\n",
        "Lets profile the `swap_data` kernel with Nsight Compute to see if we fixed the global memory access pattern."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "g3j_4i2GvIOv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "72bdc818-9eb1-44a4-d588-f88ae27a2235"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==PROF== Connected to process 14829 (/home/source_code/lab6/jacobi_step6)\n",
            "Error after iteration 0 = 0.00781058\n",
            "==PROF== Profiling \"swap_data\": 0%....50%....100% - 31 passes\n",
            "Error after iteration 25 = 0.000608074\n",
            "Error after iteration 50 = 0.000366183\n",
            "Error after iteration 75 = 0.000271309\n",
            "Error after iteration 100 = 0.000219121\n",
            "Error after iteration 125 = 0.000185581\n",
            "Error after iteration 150 = 0.000161997\n",
            "Error after iteration 175 = 0.000144383\n",
            "Error after iteration 200 = 0.000130677\n",
            "Error after iteration 225 = 0.000119665\n",
            "Error after iteration 250 = 0.000110599\n",
            "Error after iteration 275 = 0.000102984\n",
            "Success!\n",
            "Run time = 3.556 seconds\n",
            "==PROF== Disconnected from process 14829\n",
            "==PROF== Report: /home/source_code/lab6/jacobi_step6_1.ncu-rep\n"
          ]
        }
      ],
      "source": [
        "!cd /home/source_code/lab6 && ncu --launch-count 1 --launch-skip 5 -k --regex:swap_data -f -o jacobi_step6_1 --set full ./jacobi_step6"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Download the report by running the below cell and open the report via the Nsight Compute UI."
      ],
      "metadata": {
        "id": "JCPiTyC40Qyx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download('/home/source_code/lab6/jacobi_step6_1.ncu-rep')"
      ],
      "metadata": {
        "id": "qLWUpL9M0RAm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "22df5fb9-b310-4f2c-ffb9-608904aa71d8"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_d726967b-be05-4f3e-a064-4ec1259799de\", \"jacobi_step6_1.ncu-rep\", 136582)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ExWSsz1WvIOv"
      },
      "source": [
        "When comparing the `swap_data` kernel with the previous step, we can see that we fixed the memory access pattern and improved the overall performance.\n",
        "\n",
        "<!--<img src=\"images/jacobi_6_swap_base.png\" width=\"80%\">-->\n",
        "<img src=\"https://drive.google.com/uc?export=download&id=14w5rrFjyplbRfxsHysPc-vyOIlzR_G0w\">\n",
        "\n",
        "\n",
        "We are now latency bound and if you look at the *Source Counters* section, we no longer have any non-coalesced global accesses. Now,  profile the `jacobi_step` kernel with Nsight Compute."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "lnapHIO5vIOw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "876f2ad9-c42b-4ab9-f18f-af50cc09ff2c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==PROF== Connected to process 15205 (/home/source_code/lab6/jacobi_step6)\n",
            "Error after iteration 0 = 0.00781058\n",
            "==PROF== Profiling \"jacobi_step\": 0%....50%....100% - 31 passes\n",
            "Error after iteration 25 = 0.000608074\n",
            "Error after iteration 50 = 0.000366183\n",
            "Error after iteration 75 = 0.00027131\n",
            "Error after iteration 100 = 0.000219121\n",
            "Error after iteration 125 = 0.000185581\n",
            "Error after iteration 150 = 0.000161998\n",
            "Error after iteration 175 = 0.000144383\n",
            "Error after iteration 200 = 0.000130677\n",
            "Error after iteration 225 = 0.000119665\n",
            "Error after iteration 250 = 0.000110599\n",
            "Error after iteration 275 = 0.000102984\n",
            "Success!\n",
            "Run time = 3.854 seconds\n",
            "==PROF== Disconnected from process 15205\n",
            "==PROF== Report: /home/source_code/lab6/jacobi_step6_0.ncu-rep\n"
          ]
        }
      ],
      "source": [
        "!cd /home/source_code/lab6 && ncu --launch-count 1 --launch-skip 5 -k --regex:jacobi -f -o jacobi_step6_0 --set full --import-source 1 ./jacobi_step6"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Download the report by running the below cell and open the report via the Nsight Compute UI."
      ],
      "metadata": {
        "id": "PUH4rJXW0ehW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download('/home/source_code/lab6/jacobi_step6_0.ncu-rep')"
      ],
      "metadata": {
        "id": "parwlRb40hwu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gerrj6ltvIOw"
      },
      "source": [
        "Compared to the previous version of the code, the `jacobi_step` kernel did achieve a substantial improvement.\n",
        "\n",
        "<!--<img src=\"images/jacobi_6_jacobi_base.png\" width=\"80%\">-->\n",
        "<img src=\"https://drive.google.com/uc?export=download&id=1gpb4rnPbHLGQGRfJLGq97hijy9xvygxU\">\n",
        "\n",
        "\n",
        "Looking at the *Scheduler Statistics*, we see 99.9% of the cycles have no warps eligible to issue work. On cycles with no eligible warps, the issue slot is skipped and no instruction is issued. Having many skipped issue slots indicates poor latency hiding.\n",
        "\n",
        "<!--<img src=\"images/jacobi_6_jacobi_schedule.png\" width=\"80%\">-->\n",
        "<img src=\"https://drive.google.com/uc?export=download&id=11wJJbpZmgPVL9c7n7_0NDPeUG2qx7i8m\">\n",
        "\n",
        "\n",
        "The reason for this is the atomic update to the error counter inside the `jacobi_step()` kernel (`atomicAdd(error, df * df)`). If multiple threads write to the same location at the same time, they will serialize and stall. We can refactor the kernel in a way to use a more efficient reduction scheme that uses fewer overall atomics.\n",
        "\n",
        "\n",
        "**Understand and analyze** the code:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cat /home/source_code/lab6/jacobi_step7.cpp"
      ],
      "metadata": {
        "id": "2oNzDdyejmTv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e2735bef-bc4b-4595-d139-0a513359ad6e"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "// Copyright (c) 2022 NVIDIA Corporation.  All rights reserved.\n",
            "\n",
            "#include <iostream>\n",
            "#include <iomanip>\n",
            "#include <cmath>\n",
            "#include <limits>\n",
            "#include <ctime>\n",
            "#include <nvToolsExt.h>\n",
            "\n",
            "#define N 2048\n",
            "\n",
            "#define IDX(i, j) ((i) + (j) * N)\n",
            "\n",
            "// error checking macro\n",
            "#define cudaCheckErrors(msg)                                    \\\n",
            "    do {                                                        \\\n",
            "        cudaError_t __err = cudaGetLastError();                 \\\n",
            "        if (__err != cudaSuccess) {                             \\\n",
            "            fprintf(stderr, \"Fatal error: %s (%s at %s:%d)\\n\",  \\\n",
            "                    msg, cudaGetErrorString(__err),             \\\n",
            "                    __FILE__, __LINE__);                        \\\n",
            "            fprintf(stderr, \"*** FAILED - ABORTING\\n\");         \\\n",
            "            exit(1);                                            \\\n",
            "        }                                                       \\\n",
            "    } while (0)\n",
            "\n",
            "void allocate_memory (float** f, float** f_old, float** error) {\n",
            "    cudaMallocManaged(f, N * N * sizeof(float));\n",
            "    cudaMallocManaged(f_old, N * N * sizeof(float));\n",
            "    cudaMallocManaged(error, sizeof(float));\n",
            "    cudaCheckErrors(\"Memory allocation\");\n",
            "}\n",
            "\n",
            "void free_memory (float* f, float* f_old, float* error) {\n",
            "    cudaFree(f);\n",
            "    cudaFree(f_old);\n",
            "    cudaFree(error);\n",
            "    cudaCheckErrors(\"Memory deallocation\");\n",
            "}\n",
            "\n",
            "void initialize_data (float* f) {\n",
            "    // Set up simple sinusoidal boundary conditions\n",
            "    for (int j = 0; j < N; ++j) {\n",
            "        for (int i = 0; i < N; ++i) {\n",
            "\n",
            "            if (i == 0 || i == N-1) {\n",
            "                f[IDX(i,j)] = sin(j * 2 * M_PI / (N - 1));\n",
            "            }\n",
            "            else if (j == 0 || j == N-1) {\n",
            "                f[IDX(i,j)] = sin(i * 2 * M_PI / (N - 1));\n",
            "            }\n",
            "            else {\n",
            "                f[IDX(i,j)] = 0.0f;\n",
            "            }\n",
            "\n",
            "        }\n",
            "    }\n",
            "}\n",
            "\n",
            "__global__ void jacobi_step (float* f, float* f_old, float* error) {\n",
            "    int i = threadIdx.x + blockIdx.x * blockDim.x;\n",
            "    int j = threadIdx.y + blockIdx.y * blockDim.y;\n",
            "\n",
            "    float err = 0.0f;\n",
            "\n",
            "    if (j >= 1 && j <= N-2) {\n",
            "        if (i >= 1 && i <= N-2) {\n",
            "            f[IDX(i,j)] = 0.25f * (f_old[IDX(i+1,j)] + f_old[IDX(i-1,j)] +\n",
            "                                   f_old[IDX(i,j+1)] + f_old[IDX(i,j-1)]);\n",
            "\n",
            "            float df = f[IDX(i,j)] - f_old[IDX(i,j)];\n",
            "            err = df * df;\n",
            "        }\n",
            "    }\n",
            "\n",
            "    // Sum over threads in the warp\n",
            "    // For simplicity, we do this outside the above conditional\n",
            "    // so that all threads participate\n",
            "    for (int offset = 16; offset > 0; offset /= 2) {\n",
            "        err += __shfl_down_sync(0xffffffff, err, offset);\n",
            "    }\n",
            "\n",
            "    // If we're thread 0 in the warp, update our value to shared memory\n",
            "    // Note that we're assuming exactly a 32x32 block and that the warp ID\n",
            "    // is equivalent to threadIdx.y. For the general case, we would have to\n",
            "    // write more careful code.\n",
            "    __shared__ float reduction_array[32];\n",
            "    if (threadIdx.x == 0) {\n",
            "        reduction_array[threadIdx.y] = err;\n",
            "    }\n",
            "\n",
            "    // Synchronize the block before reading any values from smem\n",
            "    __syncthreads();\n",
            "\n",
            "    // Using the first warp in the block, reduce over the partial sums\n",
            "    // in the shared memory array.\n",
            "    if (threadIdx.y == 0) {\n",
            "        err = reduction_array[threadIdx.x];\n",
            "        for (int offset = 16; offset > 0; offset /= 2) {\n",
            "            err += __shfl_down_sync(0xffffffff, err, offset);\n",
            "        }\n",
            "        if (threadIdx.x == 0) {\n",
            "            atomicAdd(error, err);\n",
            "        }\n",
            "    }\n",
            "}\n",
            "\n",
            "__global__ void swap_data (float* f, float* f_old) {\n",
            "    int i = threadIdx.x + blockIdx.x * blockDim.x;\n",
            "    int j = threadIdx.y + blockIdx.y * blockDim.y;\n",
            "\n",
            "    if (j >= 1 && j <= N-2) {\n",
            "        if (i >= 1 && i <= N-2) {\n",
            "            f_old[IDX(i,j)] = f[IDX(i,j)];\n",
            "        }\n",
            "    }\n",
            "}\n",
            "\n",
            "int main () {\n",
            "    // Begin wall timing\n",
            "    std::clock_t start_time = std::clock();\n",
            "\n",
            "    float* f;\n",
            "    float* f_old;\n",
            "    float* error;\n",
            "\n",
            "    // Reserve space for the scalar field and the \"old\" copy of the data\n",
            "    nvtxRangePush(\"Allocate memory\");\n",
            "    allocate_memory(&f, &f_old, &error);\n",
            "    nvtxRangePop();\n",
            "\n",
            "    // Initialize data (we'll do this on both f and f_old, so that we don't\n",
            "    // have to worry about the boundary points later)\n",
            "    nvtxRangePush(\"Initialize data\");\n",
            "    initialize_data(f);\n",
            "    initialize_data(f_old);\n",
            "    nvtxRangePop();\n",
            "\n",
            "    // Initialize error to a large number\n",
            "    *error = std::numeric_limits<float>::max();\n",
            "    const float tolerance = 1.e-4f;\n",
            "\n",
            "    // Iterate until we're converged (but set a cap on the maximum number of\n",
            "    // iterations to avoid any possible hangs)\n",
            "    const int max_iters = 1000;\n",
            "    int num_iters = 0;\n",
            "\n",
            "    while (*error > tolerance && num_iters < max_iters) {\n",
            "        // Initialize error to zero (we'll add to it the following step)\n",
            "        *error = 0.0f;\n",
            "\n",
            "        // Perform a Jacobi relaxation step\n",
            "        nvtxRangePush(\"Jacobi step\");\n",
            "        jacobi_step<<<dim3(N / 32, N / 32), dim3(32, 32)>>>(f, f_old, error);\n",
            "        cudaDeviceSynchronize();\n",
            "        nvtxRangePop();\n",
            "\n",
            "        // Swap the old data and the new data\n",
            "        // We're doing this explicitly for pedagogical purposes, even though\n",
            "        // in this specific application a std::swap would have been OK\n",
            "        nvtxRangePush(\"Swap data\");\n",
            "        swap_data<<<dim3(N / 32, N / 32), dim3(32, 32)>>>(f, f_old);\n",
            "        cudaDeviceSynchronize();\n",
            "        nvtxRangePop();\n",
            "\n",
            "        // Normalize the L2-norm of the error by the number of data points\n",
            "        // and then take the square root\n",
            "        *error = std::sqrt(*error / (N * N));\n",
            "\n",
            "        // Periodically print out the current error\n",
            "        if (num_iters % 25 == 0) {\n",
            "            std::cout << \"Error after iteration \" << num_iters << \" = \" << *error << std::endl;\n",
            "        }\n",
            "\n",
            "        // Increment the iteration count\n",
            "        ++num_iters;\n",
            "    }\n",
            "\n",
            "    // If we took fewer than max_iters steps and the error is below the tolerance,\n",
            "    // we succeeded. Otherwise, we failed.\n",
            "\n",
            "    if (*error <= tolerance && num_iters < max_iters) {\n",
            "        std::cout << \"Success!\" << std::endl;\n",
            "    }\n",
            "    else {\n",
            "        std::cout << \"Failure!\" << std::endl;\n",
            "        return -1;\n",
            "    }\n",
            "\n",
            "    // Clean up memory allocations\n",
            "    nvtxRangePush(\"Free memory\");\n",
            "    free_memory(f, f_old, error);\n",
            "    nvtxRangePop();\n",
            "\n",
            "    // End wall timing\n",
            "    double duration = (std::clock() - start_time) / (double) CLOCKS_PER_SEC;\n",
            "    std::cout << \"Run time = \" << std::setprecision(4) << duration << \" seconds\" << std::endl;\n",
            "\n",
            "    return 0;\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, compile and profile the code."
      ],
      "metadata": {
        "id": "a-BJ43S7jm3x"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "SKx89XlPvIOw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "307d812a-0402-46a1-fa7c-f70b0c600c47"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc -o jacobi_step7 -x cu -lnvToolsExt -lineinfo jacobi_step7.cpp\n",
            "Warning: LBR backtrace method is not supported on this platform. DWARF backtrace method will be used.\n",
            "Error after iteration 0 = 0.00781059\n",
            "Error after iteration 25 = 0.000608098\n",
            "Error after iteration 50 = 0.000366206\n",
            "Error after iteration 75 = 0.000271333\n",
            "Error after iteration 100 = 0.000219136\n",
            "Error after iteration 125 = 0.000185597\n",
            "Error after iteration 150 = 0.000162008\n",
            "Error after iteration 175 = 0.000144401\n",
            "Error after iteration 200 = 0.000130694\n",
            "Error after iteration 225 = 0.00011968\n",
            "Error after iteration 250 = 0.000110613\n",
            "Error after iteration 275 = 0.000103\n",
            "Success!\n",
            "Run time = 0.7984 seconds\n",
            "Generating '/tmp/nsys-report-e56a.qdstrm'\n",
            "[1/8] [========================100%] jacobi_step7.nsys-rep\n",
            "Importer error status: Importation succeeded with non-fatal errors.\n",
            "**** Analysis failed with:\n",
            "Status: TargetProfilingFailed\n",
            "Props {\n",
            "  Items {\n",
            "    Type: DeviceId\n",
            "    Value: \"Local (CLI)\"\n",
            "  }\n",
            "}\n",
            "Error {\n",
            "  Type: RuntimeError\n",
            "  SubError {\n",
            "    Type: ProcessEventsError\n",
            "    Props {\n",
            "      Items {\n",
            "        Type: ErrorText\n",
            "        Value: \"/build/agent/work/20a3cfcd1c25021d/QuadD/Host/Analysis/Modules/TraceProcessEvent.cpp(45): Throw in function const string& {anonymous}::GetCudaCallbackName(bool, uint32_t, const QuadDAnalysis::MoreInjection&)\\nDynamic exception type: boost::exception_detail::clone_impl<QuadDCommon::InvalidArgumentException>\\nstd::exception::what: InvalidArgumentException\\n[QuadDCommon::tag_message*] = Unknown driver API function index: 673\\n\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n",
            "\n",
            "**** Errors occurred while processing the raw events. ****\n",
            "**** Please see the Diagnostics Summary page after opening the report file in GUI. ****\n",
            "[2/8] [========================100%] jacobi_step7.sqlite\n",
            "[3/8] Executing 'nvtxsum' stats report\n",
            "\n",
            "NVTX Range Statistics:\n",
            "\n",
            " Time (%)  Total Time (ns)  Instances    Avg (ns)       Med (ns)      Min (ns)     Max (ns)    StdDev (ns)   Style        Range     \n",
            " --------  ---------------  ---------  -------------  -------------  -----------  -----------  -----------  -------  ---------------\n",
            "     58.0      472,763,868          1  472,763,868.0  472,763,868.0  472,763,868  472,763,868          0.0  PushPop  Allocate memory\n",
            "     28.8      234,783,612        288      815,220.9      427,305.5      338,759   12,701,272  1,293,597.6  PushPop  Jacobi step    \n",
            "      7.7       62,657,197        288      217,559.7      228,431.5      193,361      255,806     16,099.9  PushPop  Swap data      \n",
            "      5.2       42,272,388          1   42,272,388.0   42,272,388.0   42,272,388   42,272,388          0.0  PushPop  Initialize data\n",
            "      0.3        2,286,405          1    2,286,405.0    2,286,405.0    2,286,405    2,286,405          0.0  PushPop  Free memory    \n",
            "\n",
            "[4/8] Executing 'osrtsum' stats report\n",
            "\n",
            "Operating System Runtime API Statistics:\n",
            "\n",
            " Time (%)  Total Time (ns)  Num Calls    Avg (ns)       Med (ns)     Min (ns)    Max (ns)     StdDev (ns)            Name         \n",
            " --------  ---------------  ---------  -------------  -------------  ---------  -----------  -------------  ----------------------\n",
            "     50.2    1,039,947,639          3  346,649,213.0  177,008,092.0  4,108,466  858,831,081  451,908,474.8  sem_wait              \n",
            "     40.7      843,591,811         50   16,871,836.2   10,077,379.5      3,471  100,138,305   25,758,104.0  poll                  \n",
            "      5.3      109,073,032         40    2,726,825.8    2,075,068.0     32,788   20,789,064    4,004,012.0  sem_timedwait         \n",
            "      3.6       73,569,600        520      141,480.0       14,451.5      1,113   22,587,051    1,143,806.1  ioctl                 \n",
            "      0.1        2,318,824         26       89,185.5        7,488.5      1,262    1,072,083      278,658.2  mmap                  \n",
            "      0.1        1,993,276         31       64,299.2        8,315.0      5,413    1,445,993      257,155.8  mmap64                \n",
            "      0.0          501,143         49       10,227.4        9,015.0      2,622       24,611        4,048.2  open64                \n",
            "      0.0          276,333         56        4,934.5        3,645.0      1,690       24,802        4,093.7  fopen                 \n",
            "      0.0          172,751          4       43,187.8       41,952.0     40,165       48,682        3,856.5  pthread_create        \n",
            "      0.0          133,928         14        9,566.3        8,242.0      6,888       17,673        3,205.9  putc                  \n",
            "      0.0          103,445         11        9,404.1        5,768.0      1,310       34,106        8,905.5  write                 \n",
            "      0.0           76,781         38        2,020.6        1,514.0      1,005        7,836        1,459.4  fclose                \n",
            "      0.0           76,513          6       12,752.2        8,929.0      5,176       33,778       10,933.3  fgets                 \n",
            "      0.0           44,382          8        5,547.8        4,166.0      1,057       12,209        4,532.1  fwrite                \n",
            "      0.0           35,651          9        3,961.2        3,674.0      1,598        6,303        1,703.2  munmap                \n",
            "      0.0           30,966          5        6,193.2        5,001.0      2,872       10,199        2,903.5  open                  \n",
            "      0.0           30,466          6        5,077.7        2,820.5      2,026       15,995        5,452.8  fread                 \n",
            "      0.0           30,301          2       15,150.5       15,150.5     12,170       18,131        4,215.1  socket                \n",
            "      0.0           21,887          5        4,377.4        3,487.0      1,241        9,305        3,506.5  fcntl                 \n",
            "      0.0           20,026         11        1,820.5        1,538.0      1,004        2,862          620.9  read                  \n",
            "      0.0           12,720          1       12,720.0       12,720.0     12,720       12,720            0.0  fopen64               \n",
            "      0.0           11,145          1       11,145.0       11,145.0     11,145       11,145            0.0  connect               \n",
            "      0.0            6,437          1        6,437.0        6,437.0      6,437        6,437            0.0  pthread_cond_broadcast\n",
            "      0.0            6,145          1        6,145.0        6,145.0      6,145        6,145            0.0  pipe2                 \n",
            "      0.0            5,282          2        2,641.0        2,641.0      1,747        3,535        1,264.3  fflush                \n",
            "      0.0            2,139          1        2,139.0        2,139.0      2,139        2,139            0.0  bind                  \n",
            "      0.0            1,109          1        1,109.0        1,109.0      1,109        1,109            0.0  listen                \n",
            "\n",
            "[5/8] Executing 'cudaapisum' stats report\n",
            "SKIPPED: /home/source_code/lab6/jacobi_step7.sqlite does not contain CUDA trace data.\n",
            "[6/8] Executing 'gpukernsum' stats report\n",
            "SKIPPED: /home/source_code/lab6/jacobi_step7.sqlite does not contain CUDA kernel data.\n",
            "[7/8] Executing 'gpumemtimesum' stats report\n",
            "\n",
            "CUDA Memory Operation Statistics (by time):\n",
            "\n",
            " Time (%)  Total Time (ns)  Count  Avg (ns)  Med (ns)  Min (ns)  Max (ns)  StdDev (ns)              Operation            \n",
            " --------  ---------------  -----  --------  --------  --------  --------  -----------  ---------------------------------\n",
            "     81.0        2,344,221    513   4,569.6   2,591.0     2,431    87,744      9,680.3  [CUDA Unified Memory memcpy HtoD]\n",
            "     19.0          550,518    264   2,085.3   2,016.0     1,952     6,816        552.5  [CUDA Unified Memory memcpy DtoH]\n",
            "\n",
            "[8/8] Executing 'gpumemsizesum' stats report\n",
            "\n",
            "CUDA Memory Operation Statistics (by size):\n",
            "\n",
            " Total (MB)  Count  Avg (MB)  Med (MB)  Min (MB)  Max (MB)  StdDev (MB)              Operation            \n",
            " ----------  -----  --------  --------  --------  --------  -----------  ---------------------------------\n",
            "     13.799    513     0.027     0.004     0.004     1.040        0.118  [CUDA Unified Memory memcpy HtoD]\n",
            "      1.311    264     0.005     0.004     0.004     0.061        0.007  [CUDA Unified Memory memcpy DtoH]\n",
            "\n",
            "Generated:\n",
            "    /home/source_code/lab6/jacobi_step7.qdstrm\n",
            "    /home/source_code/lab6/jacobi_step7.nsys-rep\n",
            "    /home/source_code/lab6/jacobi_step7.sqlite\n"
          ]
        }
      ],
      "source": [
        "!cd /home/source_code/lab6 && make jacobi_step7 && nsys profile --stats=true -o jacobi_step7 -f true ./jacobi_step7"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Download the report by running the below cell and open the report via the Nsight Systems UI."
      ],
      "metadata": {
        "id": "Pq1cWEoj0pXg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download('/home/source_code/lab6/jacobi_step7.nsys-rep')"
      ],
      "metadata": {
        "id": "TfqH77Dd0rip",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "88458fa0-25bb-4eac-f678-71c291914fb7"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_e42adfb6-e0b2-45c9-8049-cda880c2b9fe\", \"jacobi_step7.nsys-rep\", 264784)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jVLpqeQsvIOw"
      },
      "source": [
        "We managed to reduce the total execution time enormously. Profile the `jacobi_step()` kernel with Nsight Compute to investigate more."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "ViePcJuOvIOw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "63e8702e-47ed-4016-9a93-fa6241cce81a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==PROF== Connected to process 16182 (/home/source_code/lab6/jacobi_step7)\n",
            "Error after iteration 0 = 0.00781059\n",
            "==PROF== Profiling \"jacobi_step\": 0%....50%....100% - 31 passes\n",
            "Error after iteration 25 = 0.000608098\n",
            "Error after iteration 50 = 0.000366206\n",
            "Error after iteration 75 = 0.000271333\n",
            "Error after iteration 100 = 0.000219136\n",
            "Error after iteration 125 = 0.000185597\n",
            "Error after iteration 150 = 0.000162008\n",
            "Error after iteration 175 = 0.000144401\n",
            "Error after iteration 200 = 0.000130694\n",
            "Error after iteration 225 = 0.00011968\n",
            "Error after iteration 250 = 0.000110613\n",
            "Error after iteration 275 = 0.000103\n",
            "Success!\n",
            "Run time = 1.268 seconds\n",
            "==PROF== Disconnected from process 16182\n",
            "==PROF== Report: /home/source_code/lab6/jacobi_step7_0.ncu-rep\n"
          ]
        }
      ],
      "source": [
        "!cd /home/source_code/lab6 && ncu --launch-count 1 --launch-skip 5 -k --regex:jacobi -f -o jacobi_step7_0 --set full --import-source 1 ./jacobi_step7"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Download the report by running the below cell and open the report via the Nsight Compute UI."
      ],
      "metadata": {
        "id": "mGkZ8IYi00ko"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download('/home/source_code/lab6/jacobi_step7_0.ncu-rep')"
      ],
      "metadata": {
        "id": "-Am0hg_Q096s",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "ee9dff6d-e619-49db-f496-d0c739873f24"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_97c43f86-9599-4f9a-a61e-c144e3fda3f9\", \"jacobi_step7_0.ncu-rep\", 207973)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "96vxjBA9vIOw"
      },
      "source": [
        "<!--<img src=\"images/jacobi_7_sol.png\" width=\"80%\">-->\n",
        "<img src=\"https://drive.google.com/uc?export=download&id=1MxvgMKvTi-AdN_ijeoh9Fgwu8MqgOIM8\">\n",
        "\n",
        "\n",
        "The *GPU Speed of Light* section shows we increase both compute and memory utilization compared to the previous section. Moreover, the Roofline charts shows an improvement in performance and an increase in arithmetic intensity.\n",
        "\n",
        "<!--<img src=\"images/jacobi_7_roof.png\" width=\"80%\">-->\n",
        "<img src=\"https://drive.google.com/uc?export=download&id=1Hp8zLPe2pK8L6_2gAHcmjFEVFR1ueuLH\">\n",
        "\n",
        "\n",
        "Comparing the `jacobi_step` and `swap_data` kernel, one has more dynamic random-access memory (DRAM) throughput than the `jacobi_step` kernel.\n",
        "\n",
        "<!--<img src=\"images/jacobi_7_base.png\" width=\"80%\">-->\n",
        "<img src=\"https://drive.google.com/uc?export=download&id=19U4_i56GV85iCr9EPQmFfklaLC50fS-0\">\n",
        "\n",
        "\n",
        "### Step 7: Shared Memory\n",
        "Although the code runs faster, there are still uncoalesced accesses that we need to address. The issue with the stencil operations is the cache reuse and as the array (problem size) grows, due to the stride between row `j` and row `j+1` , there will be less cache reuse. To solve this issue, we can read the data from the shared memory which is closer to the GPU cores. This will result in accessing the DRAM less. We implement the simplest version for ease but this might not be the best solution. To learn more on how to understand and optimize shared memory accesses using Nsight Compute, please watch the [GTC talk](https://www.nvidia.com/en-us/on-demand/session/gtcspring22-s41723/).\n",
        "\n",
        "\n",
        "**Understand and analyze** the code:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cat /home/source_code/lab6/jacobi_step8.cpp"
      ],
      "metadata": {
        "id": "7PPIlsgokhX_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, compile and profile the code."
      ],
      "metadata": {
        "id": "kyot5CLbkiMG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "nEEf1RqAvIOx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8f49d40a-5743-4df5-c618-dce45b413787"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc -o jacobi_step8 -x cu -lnvToolsExt -lineinfo jacobi_step8.cpp\n",
            "Warning: LBR backtrace method is not supported on this platform. DWARF backtrace method will be used.\n",
            "Error after iteration 0 = 0.00781059\n",
            "Error after iteration 25 = 0.000608098\n",
            "Error after iteration 50 = 0.000366206\n",
            "Error after iteration 75 = 0.000271333\n",
            "Error after iteration 100 = 0.000219136\n",
            "Error after iteration 125 = 0.000185597\n",
            "Error after iteration 150 = 0.000162008\n",
            "Error after iteration 175 = 0.000144401\n",
            "Error after iteration 200 = 0.000130694\n",
            "Error after iteration 225 = 0.00011968\n",
            "Error after iteration 250 = 0.000110613\n",
            "Error after iteration 275 = 0.000103\n",
            "Success!\n",
            "Run time = 0.7491 seconds\n",
            "Generating '/tmp/nsys-report-f8d5.qdstrm'\n",
            "[1/8] [========================100%] jacobi_step8.nsys-rep\n",
            "Importer error status: Importation succeeded with non-fatal errors.\n",
            "**** Analysis failed with:\n",
            "Status: TargetProfilingFailed\n",
            "Props {\n",
            "  Items {\n",
            "    Type: DeviceId\n",
            "    Value: \"Local (CLI)\"\n",
            "  }\n",
            "}\n",
            "Error {\n",
            "  Type: RuntimeError\n",
            "  SubError {\n",
            "    Type: ProcessEventsError\n",
            "    Props {\n",
            "      Items {\n",
            "        Type: ErrorText\n",
            "        Value: \"/build/agent/work/20a3cfcd1c25021d/QuadD/Host/Analysis/Modules/TraceProcessEvent.cpp(45): Throw in function const string& {anonymous}::GetCudaCallbackName(bool, uint32_t, const QuadDAnalysis::MoreInjection&)\\nDynamic exception type: boost::exception_detail::clone_impl<QuadDCommon::InvalidArgumentException>\\nstd::exception::what: InvalidArgumentException\\n[QuadDCommon::tag_message*] = Unknown driver API function index: 673\\n\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n",
            "\n",
            "**** Errors occurred while processing the raw events. ****\n",
            "**** Please see the Diagnostics Summary page after opening the report file in GUI. ****\n",
            "[2/8] [========================100%] jacobi_step8.sqlite\n",
            "[3/8] Executing 'nvtxsum' stats report\n",
            "\n",
            "NVTX Range Statistics:\n",
            "\n",
            " Time (%)  Total Time (ns)  Instances    Avg (ns)       Med (ns)      Min (ns)     Max (ns)    StdDev (ns)   Style        Range     \n",
            " --------  ---------------  ---------  -------------  -------------  -----------  -----------  -----------  -------  ---------------\n",
            "     64.4      492,684,791          1  492,684,791.0  492,684,791.0  492,684,791  492,684,791          0.0  PushPop  Allocate memory\n",
            "     21.7      165,718,255        288      575,410.6      526,045.5      390,289   14,042,967    870,488.7  PushPop  Jacobi step    \n",
            "      8.0       61,110,004        288      212,187.5      228,408.5      184,282      370,311     24,089.4  PushPop  Swap data      \n",
            "      5.7       43,350,030          1   43,350,030.0   43,350,030.0   43,350,030   43,350,030          0.0  PushPop  Initialize data\n",
            "      0.3        2,301,430          1    2,301,430.0    2,301,430.0    2,301,430    2,301,430          0.0  PushPop  Free memory    \n",
            "\n",
            "[4/8] Executing 'osrtsum' stats report\n",
            "\n",
            "Operating System Runtime API Statistics:\n",
            "\n",
            " Time (%)  Total Time (ns)  Num Calls    Avg (ns)       Med (ns)     Min (ns)    Max (ns)     StdDev (ns)        Name     \n",
            " --------  ---------------  ---------  -------------  -------------  ---------  -----------  -------------  --------------\n",
            "     50.9      986,770,276          3  328,923,425.3  178,305,560.0  3,505,510  804,959,206  421,421,775.3  sem_wait      \n",
            "     40.4      783,759,217         44   17,812,709.5   10,077,725.0      3,928  100,136,814   27,337,199.9  poll          \n",
            "      4.8       93,040,040         35    2,658,286.9    2,076,606.0     54,066   20,750,303    4,005,750.4  sem_timedwait \n",
            "      3.7       71,283,902        520      137,084.4       14,980.0      1,053   18,824,302    1,062,750.0  ioctl         \n",
            "      0.1        2,340,513         26       90,019.7        7,729.0      1,361    1,125,026      280,802.3  mmap          \n",
            "      0.1        1,441,506         31       46,500.2        8,755.0      4,529      934,423      165,514.1  mmap64        \n",
            "      0.0          499,436         49       10,192.6        9,291.0      2,459       33,657        4,398.8  open64        \n",
            "      0.0          314,298         56        5,612.5        4,271.0      1,786       20,471        4,288.0  fopen         \n",
            "      0.0          206,833          4       51,708.3       48,668.0     43,609       65,888        9,918.7  pthread_create\n",
            "      0.0          119,774         14        8,555.3        8,324.0      5,568       12,370        1,741.7  putc          \n",
            "      0.0          109,407         11        9,946.1        6,890.0      1,600       36,627        9,853.9  write         \n",
            "      0.0           91,372          6       15,228.7       10,544.0      5,407       41,700       13,786.8  fgets         \n",
            "      0.0           80,172         41        1,955.4        1,578.0      1,014        6,920        1,086.5  fclose        \n",
            "      0.0           41,832          6        6,972.0        5,571.0      1,420       17,167        6,280.1  fwrite        \n",
            "      0.0           33,182          9        3,686.9        3,447.0      1,741        6,392        1,669.4  munmap        \n",
            "      0.0           31,572          5        6,314.4        5,238.0      2,920       10,328        2,959.7  open          \n",
            "      0.0           27,825          2       13,912.5       13,912.5      9,384       18,441        6,404.3  socket        \n",
            "      0.0           24,903         13        1,915.6        1,650.0      1,000        3,436          764.8  read          \n",
            "      0.0           18,300          6        3,050.0        2,556.5      2,430        4,647          903.4  fread         \n",
            "      0.0           10,752          4        2,688.0        2,239.5      1,159        5,114        1,853.4  fcntl         \n",
            "      0.0           10,693          1       10,693.0       10,693.0     10,693       10,693            0.0  connect       \n",
            "      0.0            8,408          1        8,408.0        8,408.0      8,408        8,408            0.0  fopen64       \n",
            "      0.0            6,611          1        6,611.0        6,611.0      6,611        6,611            0.0  pipe2         \n",
            "      0.0            3,682          1        3,682.0        3,682.0      3,682        3,682            0.0  fflush        \n",
            "      0.0            2,472          1        2,472.0        2,472.0      2,472        2,472            0.0  bind          \n",
            "      0.0            1,174          1        1,174.0        1,174.0      1,174        1,174            0.0  listen        \n",
            "\n",
            "[5/8] Executing 'cudaapisum' stats report\n",
            "SKIPPED: /home/source_code/lab6/jacobi_step8.sqlite does not contain CUDA trace data.\n",
            "[6/8] Executing 'gpukernsum' stats report\n",
            "SKIPPED: /home/source_code/lab6/jacobi_step8.sqlite does not contain CUDA kernel data.\n",
            "[7/8] Executing 'gpumemtimesum' stats report\n",
            "\n",
            "CUDA Memory Operation Statistics (by time):\n",
            "\n",
            " Time (%)  Total Time (ns)  Count  Avg (ns)  Med (ns)  Min (ns)  Max (ns)  StdDev (ns)              Operation            \n",
            " --------  ---------------  -----  --------  --------  --------  --------  -----------  ---------------------------------\n",
            "     85.8        3,623,648    859   4,218.4   2,591.0     2,399    88,224      8,661.9  [CUDA Unified Memory memcpy HtoD]\n",
            "     14.2          600,891    292   2,057.8   1,984.0     1,888     6,944        564.2  [CUDA Unified Memory memcpy DtoH]\n",
            "\n",
            "[8/8] Executing 'gpumemsizesum' stats report\n",
            "\n",
            "CUDA Memory Operation Statistics (by size):\n",
            "\n",
            " Total (MB)  Count  Avg (MB)  Med (MB)  Min (MB)  Max (MB)  StdDev (MB)              Operation            \n",
            " ----------  -----  --------  --------  --------  --------  -----------  ---------------------------------\n",
            "     19.116    859     0.022     0.004     0.004     1.044        0.105  [CUDA Unified Memory memcpy HtoD]\n",
            "      1.425    292     0.005     0.004     0.004     0.061        0.007  [CUDA Unified Memory memcpy DtoH]\n",
            "\n",
            "Generated:\n",
            "    /home/source_code/lab6/jacobi_step8.qdstrm\n",
            "    /home/source_code/lab6/jacobi_step8.nsys-rep\n",
            "    /home/source_code/lab6/jacobi_step8.sqlite\n"
          ]
        }
      ],
      "source": [
        "!cd /home/source_code/lab6 && make jacobi_step8 && nsys profile --stats=true -o jacobi_step8 -f true ./jacobi_step8"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Download the report by running the below cell and open the report via the Nsight Systems UI."
      ],
      "metadata": {
        "id": "7m0Q8crYDItQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download('/home/source_code/lab6/jacobi_step8.nsys-rep')"
      ],
      "metadata": {
        "id": "FQaURxDxDJDa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "6674a00c-c160-47bd-cb5f-9a992d0911a5"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_572d95d0-297e-43d7-b929-ba4fc2a74d18\", \"jacobi_step8.nsys-rep\", 269229)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EHmKpz5ivIOx"
      },
      "source": [
        "Profile the kernel with Nsight Compute and inspect it further."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "-zjiXYaQvIOx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8556ddf1-5813-4edd-ddaf-7002bc4a148e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==PROF== Connected to process 17286 (/home/source_code/lab6/jacobi_step8)\n",
            "Error after iteration 0 = 0.00781059\n",
            "==PROF== Profiling \"jacobi_step\": 0%....50%....100% - 31 passes\n",
            "Error after iteration 25 = 0.000608098\n",
            "Error after iteration 50 = 0.000366206\n",
            "Error after iteration 75 = 0.000271333\n",
            "Error after iteration 100 = 0.000219136\n",
            "Error after iteration 125 = 0.000185597\n",
            "Error after iteration 150 = 0.000162008\n",
            "Error after iteration 175 = 0.000144401\n",
            "Error after iteration 200 = 0.000130694\n",
            "Error after iteration 225 = 0.00011968\n",
            "Error after iteration 250 = 0.000110613\n",
            "Error after iteration 275 = 0.000103\n",
            "Success!\n",
            "Run time = 1.174 seconds\n",
            "==PROF== Disconnected from process 17286\n",
            "==PROF== Report: /home/source_code/lab6/jacobi_step8_0.ncu-rep\n"
          ]
        }
      ],
      "source": [
        "!cd /home/source_code/lab6 && ncu --launch-count 1 --launch-skip 5 -k --regex:jacobi --export jacobi_step8_0 --force-overwrite --set full ./jacobi_step8"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Download the report by running the below cell and open the report via the Nsight Compute UI."
      ],
      "metadata": {
        "id": "XLZHu4uWDZfE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download('/home/source_code/lab6/jacobi_step8_0.ncu-rep')"
      ],
      "metadata": {
        "id": "dHuwETnvDd6j",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "d755d8d9-a589-48fa-c33c-14db0a4c70a8"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_a87321e9-4822-49cf-bb0f-6be932ce5088\", \"jacobi_step8_0.ncu-rep\", 190063)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pYvlEL6SvIOx"
      },
      "source": [
        "\n",
        "<!--<img src=\"images/jacobi_8_sol.png\" width=\"80%\">-->\n",
        "<img src=\"https://drive.google.com/uc?export=download&id=1GL_RQTscRUg0CuXQI-aUpK_kuJiGemvr\">\n",
        "\n",
        "\n",
        "We achieved better compute and memory utilization compared to the previous section and memory access patterns are fully coalesced.\n",
        "\n",
        "\n",
        "<!--<img src=\"images/jacobi_8_source.png\" width=\"80%\">-->\n",
        "<img src=\"https://drive.google.com/uc?export=download&id=1mcjFV8X_BHHum8HmhNyW35hrukFsUIY5\">\n",
        "\n",
        "The Nsight Systems profiler report shows how fast the kernels are. However, take to account that you might have to increase the problem size again as once again the device warmup might be a performance limiter.\n",
        "\n",
        "<!--<img src=\"images/jacobi_8_nsight.png\" width=\"80%\">-->\n",
        "<img src=\"https://drive.google.com/uc?export=download&id=11zMfgCJIMOoJs_RZcq6nkG_KZKskPTDW\">"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Advanced Topics"
      ],
      "metadata": {
        "id": "kti060Y0w9de"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3aTP7n1-vIOy"
      },
      "source": [
        "## Learning objectives\n",
        "The **goal** of this lab is to:\n",
        "\n",
        "- Learn about tracing of Message Passing Interface (MPI), OpenSHMEM, NVSHMEM™ and NVIDIA Collective Communication Library (NCCL)\n",
        "- Learn how to do multi-process profiling\n",
        "\n",
        "We do not intend to cover:\n",
        "\n",
        "- How to use NVSHMEM, NCCL, and MPI\n",
        "\n",
        "### NVIDIA Nsight Systems\n",
        "NVIDIA Nsight™ Systems tool offers system-wide performance analysis to visualize the application’s algorithms, help identify optimization opportunities, and improve the performance of applications running on a system consisting of multiple CPUs and GPUs. Nsight Systems is packed with many features. A few of the features highlighted in the above screenshot:\n",
        "\n",
        "- Application programming interface (API) tracing of CUDA libraries and deep learning frameworks\n",
        "- CPU utilization, CPU thread states and thread migration as well as CPU callstack sampling\n",
        "- Operating system (OS) runtime library calls\n",
        "- GPU activities (kernels and memory copies) as well as GPU metrics\n",
        "\n",
        "This section briefly explores other features of Nsight Systems that were not covered as part of the other labs.\n",
        "\n",
        "#### GPU Metrics Sampling\n",
        "\n",
        "Nsight Systems has a GPU Metrics feature that is used to identify performance limiters in applications using GPU for computations. It uses periodic sampling to gather performance metrics and detailed timing statistics associated with different GPU hardware units taking advantage of specialized hardware to capture this data in a single pass with minimal overhead. These metrics provide an overview of GPU efficiency over time within compute and input/output (I/O) activities:\n",
        "\n",
        "- I/O throughputs: PCIe, NVLink, and dynamic random access memory (DRAM)\n",
        "- Streaming Multiprocessor / Shared Processor (SM) utilization: SMs activity, Tensor Core activity, instructions issued, warp occupancy (including unallocated slots)\n",
        "\n",
        "These metrics can also help users answer the common questions:\n",
        "\n",
        "- Is my GPU idle?\n",
        "- Is my instruction rate low (possibly IO bound)?\n",
        "- Is my GPU full? Sufficient kernel grids size and streams? Are my SMs and warp slots full?\n",
        "- Can I see GPU Direct Remote Direct Memory Acccess (RDMA)/Storage or other transfers?\n",
        "- Am I using TensorCores?\n",
        "- Am I possibly blocked on I/O, or number of warps, etc?\n",
        "\n",
        "Nsight Sytems GPU Metrics require NVIDIA GPUs with the Turing™ architecture or newer. Learn more about GPU metrics at https://docs.nvidia.com/nsight-systems/UserGuide/index.html#gpu-metric-sampling\n",
        "\n",
        "<!--<img src=\"images/gpu_metrics.png\">-->\n",
        "<img src=\"https://drive.google.com/uc?export=download&id=1F9kGVB3KHOsSGvfgsxDOeKKzE5K0U_2O\">\n",
        "\n",
        "\n",
        "#### TRACING OF MPI, OpenSHMEM, NVSHMEM AND NCCL\n",
        "\n",
        "Nsight Systems supports MPI as well as OpenSHMEM tracing. You can record MPI communication parameters and track the MPI communicators. So, if you want to follow the data and see which MPI ranks are communicating with each other and how much data is transferred, you can see this information in the report.\n",
        "\n",
        "<!--<img src=\"images/mpi_comm.png\">-->\n",
        "<img src=\"https://drive.google.com/uc?export=download&id=1wBtIVybtVjPGFlMcl16WfI9iXcT9Bm5L\">\n",
        "\n",
        "\n",
        "In the above screenshot you see the tooltip for an `MPI_Irecv` (bottom right) with its MPI tag, the number of bytes that have been received, the sender of the data, and also the communicator. In the case of MPI, you can also trace MPI for Fortran applications.\n",
        "\n",
        "Besides MPI and OpenSHMEM, where we intercept the library calls, Nsight Systems can also trace calls into NVSHMEM and NCCL libraries based on NVIDIA Tools Extension SDK (NVTX) as explained in previous labs. The result looks similar to what is shown in the above screenshot, with the function names of the respective API and the respective row labels, e.g. NCCL and NVSHMEM rows instead of MPI and UCX as in the above screenshot.\n",
        "\n",
        "In the screenshot, you see the execution timeline of a super short range of an MPI program which triggers some `MPI_Isends` and `MPI_Irecvs`. For each MPI call you get the communication parameters and you also get the Unified Communication X (UCX) API calls, which are triggered by the MPI implementation, which in this example is OpenMPI.\n",
        "\n",
        "\n",
        "#### UCX API TRACING\n",
        "\n",
        "The UCX layer is an open-source communication framework that acts as a common library and API for several higher-level communication libraries, for example Open MPI (including its OpenSHMEM implementation) and MPICH. If UCX library trace is selected Nsight Systems will trace the subset of functions of the UC Protocol (UDP) layer that are most likely involved in performance bottlenecks. If OpenSHMEM library trace is selected, Nsight Systems will trace the subset of OpenSHMEM API functions that are most likely involved in performance bottlenecks.\n",
        "\n",
        "<!--<img src=\"images/ucx.png\">-->\n",
        "<img src=\"https://drive.google.com/uc?export=download&id=19BClqtSEB0pYJ4ghp6cvKA_h1vAWc3i5\">\n",
        "\n",
        "\n",
        "In the above screenshot, we have both `MPI_Isend` and `MPI_Irecv` calls that trigger UCP API calls (you only see the `MPI_Isend` calls, because the `MPI_Irecv` calls are super short for this particular example). The bottom row in the timeline shows the processing of transfers from non-blocking UCP communication operations. In the UCX row, you see the submit functions and in the row below you see when the processing of the transfers starts (if we were to zoom out, we could also see when the processing ends).\n",
        "\n",
        "#### NIC Performance Metrics\n",
        "NVIDIA ConnectX® smart network interface cards (smart NICs) offer advanced hardware offloads and accelerations for network operations. Viewing smart NICs metrics on Nsight Systems timeline enables developers to better understand their application’s network usage and use this information to optimize the application’s performance.\n",
        "\n",
        "<!--<img src=\"images/NIC.png\"> -->\n",
        "<img src=\"https://drive.google.com/uc?export=download&id=1gq1GKYx71JxSlnUeaL7F-US4rmj5E_Qs\">\n",
        "\n",
        "\n",
        "The performance counters are displayed over the Nsight Systems timeline, letting you know when the application is sending and receiving data. There are also counters that indicate network congestion like the `IB Send Wait` counter that you see in the above screenshot.\n",
        "\n",
        "### Nsight Systems Multi-Process Profiling\n",
        "\n",
        "On compute clusters where you have to use a workload manager or want to do a run over multiple nodes, the `nsys profile` command is prefixed before the application. With this, a report file is generated for each process. If you can launch your application without a workload manager on a single node (e.g. with `mpirun`), you can prefix `nsys profile` before `mpirun` and a single report including all processes is generated.\n",
        "\n",
        "- **Single Node**: `nsys profile [nsys_args] mpirun [mpirun_args] your_executable`. The command will create one report file.\n",
        "- **Multiple Nodes**: `mpirun [mpirun_args] nsys profile [nsys_args] your_executable`, you can set output report name with `-o report_name_%q{OMPI_COMM_WORLD_RANK}`. (For OpenMPI, PMI_RANK for MPICH and SLURM_PROCID for Slurm). The command will create one report file per MPI rank.\n",
        "\n",
        "You can also profile only specific ranks:\n",
        "\n",
        "```\n",
        "#!/bin/bash\n",
        "# OMPI_COMM_WORLD_LOCAL_RANK for node local rank\n",
        "if [ $OMPI_COMM_WORLD_RANK -eq 0 ]; then\n",
        "    nsys profile -t mpi \"$@\"\n",
        "else\n",
        "    \"$@\"\n",
        "fi\n",
        "```\n",
        "\n",
        "Below is an example command that was run on a compute facility that uses the *SLURM* workload manager using two nodes.\n",
        "\n",
        "```\n",
        "srun [SRUN_ARGS] nsys profile -t mpi,ucx -s none --nic-metrics=true -o ./report_mpi.%q{SLURM_PROCID} -f true ./myprogram [PROGRAM_ARGS]\n",
        "```\n",
        "\n",
        "where,\n",
        "\n",
        "- `nsys profile`: starts a profiling session\n",
        "- `-t, --trace=...`: sets the APIs to be traced, in this example, it is UCX and MPI\n",
        "- `-s,--sample=[cpu|none]`: controls CPU IP sampling\n",
        "- `--nic-metrics=[true|false]`: controls Network Interface Cards (NIC) metrics collection\n",
        "- `-o, --output=report#`: output profile report file path; and\n",
        "- `-f --force-overwrite`: overwrite the output report file, if it already exists\n",
        "\n",
        "To learn more about other switches to use with `nsys profile`, you can type `nsys profile --help` on the command line or read the [online docs](https://docs.nvidia.com/nsight-systems/UserGuide/index.html#cli-profiling).\n",
        "\n",
        "### Nsight Compute Multi-Process Profiling\n",
        "\n",
        "On a single-node submission, one Nsight Compute instance can profile all launched child processes with the data for all processes stored in one report file.\n",
        "\n",
        "`ncu --target-processes all -o <singlereport-name> <app> <args>`\n",
        "\n",
        "On multi-node submissions, one tool instance can be used per node. Make sure instances don’t write to the same report file on a shared disk.\n",
        "\n",
        "`ncu -o report_%q{OMPI_COMM_WORLD_RANK} <app> <args>`\n",
        "\n",
        "Similar to Nsight Systems, consider profiling only a single rank, for example using a wrapper script (see below example)\n",
        "\n",
        "```\n",
        "#!/bin/bash\n",
        "if [[ \"$OMPI_COMM_WORLD_RANK\" == \"3\" ]] ; then\n",
        "    /sw/cluster/cuda/11.1/ nsight-compute/ncu -o report_${OMPI_COMM_WORLD_RANK} --target-processes all $*\n",
        "else\n",
        "    $*\n",
        "fi\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wo-o4WMFvIOy"
      },
      "source": [
        "# Links and Resources\n",
        "\n",
        "\n",
        "[NVIDIA Nsight System](https://docs.nvidia.com/nsight-systems/)\n",
        "\n",
        "[NVIDIA Nsight Compute](https://docs.nvidia.com/nsight-compute/index.html)\n",
        "\n",
        "[CUDA Toolkit Documentation](https://docs.nvidia.com/cuda/)\n",
        "\n",
        "**NOTE**: To be able to see the Nsight Systems and Compute profiler outputs, please download the latest versions from the below pages:\n",
        "\n",
        "- https://developer.nvidia.com/nsight-systems\n",
        "- https://developer.nvidia.com/nsight-compute\n",
        "\n",
        "\n",
        "Don't forget to check out additional [Open Hackathons Resources](https://www.openhackathons.org/s/technical-resources) and join our [OpenACC and Hackathons Slack Channel](https://www.openacc.org/community#slack) to share your experience and get more help from the community.\n",
        "\n",
        "---\n",
        "\n",
        "## Licensing\n",
        "\n",
        "Copyright © 2022 OpenACC-Standard.org.  This material is released by OpenACC-Standard.org, in collaboration with NVIDIA Corporation, under the Creative Commons Attribution 4.0 International (CC BY 4.0). These materials may include references to hardware and software developed by other entities; all applicable licensing and copyrights apply."
      ]
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "vUxmly7CPGIr",
        "BvuztjS_yLJ4",
        "kti060Y0w9de"
      ],
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}